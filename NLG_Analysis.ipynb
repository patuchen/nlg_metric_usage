{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization\n",
        "Import the necessary libraries and authenticate the user to access the Google Sheet:"
      ],
      "metadata": {
        "id": "TwgwMiUccT8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'Category': ['A', 'B', 'C', 'D'],\n",
        "    'Value1': [10, 15, 20, 10],\n",
        "    'Value2': [5, 10, 5, 10],\n",
        "    'Value3': [15, 5, 10, 5]\n",
        "})\n",
        "\n",
        "# Custom order for each category\n",
        "custom_orders = {\n",
        "    'A': ['Value3', 'Value1', 'Value2'],\n",
        "    'B': ['Value2', 'Value3', 'Value1'],\n",
        "    'C': ['Value1', 'Value2', 'Value3'],\n",
        "    'D': ['Value3', 'Value2', 'Value1']\n",
        "}\n",
        "\n",
        "# Colors for each value\n",
        "colors = {\n",
        "    'Value1': 'skyblue',\n",
        "    'Value2': 'orange',\n",
        "    'Value3': 'green'\n",
        "}\n",
        "\n",
        "def plot_stacked_barh(data, custom_orders, colors):\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    for idx, row in data.iterrows():\n",
        "        category = row['Category']\n",
        "        order = custom_orders[category]\n",
        "\n",
        "        # Initialize the cumulative values for the custom order\n",
        "        left = 0\n",
        "        for value in order:\n",
        "            ax.barh(category, row[value], left=left, color=colors[value], label=value if idx == 0 else \"\")\n",
        "            left += row[value]\n",
        "\n",
        "    # Adding labels\n",
        "    ax.set_xlabel('Values')\n",
        "    ax.set_ylabel('Categories')\n",
        "    ax.set_title('Horizontal Stacked Bar Chart with Custom Orders')\n",
        "\n",
        "    # Avoid duplicate labels in legend\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    unique_labels = dict(zip(labels, handles))\n",
        "    ax.legend(unique_labels.values(), unique_labels.keys())\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plotting the chart\n",
        "plot_stacked_barh(data, custom_orders, colors)\n"
      ],
      "metadata": {
        "id": "dwwU-peU8lme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6KKSyKqryKJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  ADDING CODE ANALYSIS BEFORE the original analysis so original analysis may overwrite code variables but not the other way\n",
        "\n",
        "# WORKS ONLY IN Google Colab\n",
        "\n",
        "# Sheet names to analyze\n",
        "INLG_2023_PAPERS = \"INLG 2023 Papers\"\n",
        "GENERATION = \"Generation\"\n",
        "CODE_SHEETS = [INLG_2023_PAPERS, GENERATION]\n",
        "# CODE_SHEETS = [\"INLG 2023 Papers\"]\n",
        "\n",
        "# List the column names as constants to prevent typos\n",
        "TITLE = \"Title\"\n",
        "ACL_ID = \"ACL ID\"\n",
        "PAPER_TYPE = \"Paper Type\"\n",
        "PAPER_LINK = \"Paper Link\"\n",
        "CHECKED_BY = \"Checked By\"\n",
        "COMPLETE = \"Complete\"\n",
        "LINK_TO_CODE = \"Link to Code\"  #github, some other url, \"None first view\"\n",
        "NONE_FIRST_VIEW = \"None first view\"  # value of LINK_TO_CODE if no code was found\n",
        "PROMISED_DELIVERED = \"Promised Delivered\"\n",
        "INSTALLATION = \"Installation\"\n",
        "EXPERIMENTS_COVERED = \"Experiments Covered\"\n",
        "SCRIPTS_DOCUMENTATION = \"Scripts Documentation\"\n",
        "BEST_PRACTICES = \"Best Practices\"\n",
        "ACADEMIA_INDUSTRY = \"Academia/Industry\"\n",
        "STARS = \"stars\"\n",
        "Citations = \"Citations\"\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sheet2df(sheet):\n",
        "  worksheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1NU6IlxhYg515RLjsVxNW5FS0ChWbIKi3yrrdfqEvsRM/').worksheet(sheet)\n",
        "\n",
        "  # get_all_values gives a list of rows.\n",
        "  rows = worksheet.get_all_values()\n",
        "\n",
        "  # Convert to a DataFrame and render.\n",
        "  df = pd.DataFrame.from_records(rows[1:], columns=rows[0])\n",
        "  return df\n",
        "\n",
        "codedfs = {sheet: sheet2df(sheet) for sheet in CODE_SHEETS}\n",
        "\n",
        "\n",
        "# RUN THE CELL ABOVE AND save the files or load them if you are on google colab or local\n",
        "# from google.colab import files\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "\n",
        " # XX secret token please use responsibly or ideally replace by your own token - any token will work\n",
        "secret_token = \"XXXXXX\"\n",
        "\n",
        "def get_github_stars(url):\n",
        "    try:\n",
        "        # Parse the URL to get the path\n",
        "        path = urlparse(url).path\n",
        "        # Split the path to get the repository owner and name\n",
        "        owner, repo = path.strip(\"/\").split(\"/\")[0:2]\n",
        "        # Make a GET request to the GitHub API\n",
        "        response = requests.get(f\"https://api.github.com/repos/{owner}/{repo}\", auth=(\"xx\", secret_token))\n",
        "        # Extract the number of stars from the response\n",
        "        stars = response.json()[\"stargazers_count\"]\n",
        "    except Exception as e:\n",
        "        print(f\"{url=} {owner=} {repo=}\\n{response.json()=}\\n{e}\", flush=True)\n",
        "        raise e\n",
        "    return stars\n",
        "\n",
        "if codedfs is not None:  # Hack to detect that we are in google colab where the gsheet api works\n",
        "    from google.colab import files\n",
        "\n",
        "    for sheet in codedfs:\n",
        "        df = codedfs[sheet]\n",
        "        df[PROMISED_DELIVERED] = df[PROMISED_DELIVERED].astype(str)\n",
        "        df['stars'] = df[~df[PROMISED_DELIVERED].str.contains('404') & df[LINK_TO_CODE].str.contains('github')][LINK_TO_CODE].apply(get_github_stars)\n",
        "\n",
        "        ##### HERE YOU CAN SAVE THE DATA AND LOAD THEM AGAIN\n",
        "        # codedfs[sheet].to_csv(f\"{sheet}.csv\")\n",
        "        # files.download(f\"{sheet}.csv\")\n",
        "else:\n",
        "    #  assuming you have downloaded the files loads them\n",
        "    codedfs = {}\n",
        "    for sheet in CODE_SHEETS:\n",
        "        codedfs[sheet] = pd.read_csv(f\"{sheet}.csv\")\n",
        "\n",
        "# codedfs[INLG_2023_PAPERS].head()"
      ],
      "metadata": {
        "id": "rYRYMS9IB1-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codedfs[INLG_2023_PAPERS].head(3)"
      ],
      "metadata": {
        "id": "wM5mbydzG95D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the histograms\n",
        "inlgcdf = codedfs[INLG_2023_PAPERS]\n",
        "aclcdf = codedfs[GENERATION]\n",
        "\n",
        "from numpy import log10\n",
        "\n",
        "logone = lambda x: log10(x+1)\n",
        "inv_logone = lambda x: 10**x - 1\n",
        "\n",
        "\n",
        "print(inlgcdf[inlgcdf[\"Paper Type\"] == \"Long\"][\"stars\"].mean())\n",
        "print(inlgcdf[inlgcdf[\"Paper Type\"] == \"Long\"][\"stars\"].median())\n",
        "print(inlgcdf[inlgcdf[\"Paper Type\"] == \"Short\"][\"stars\"].mean())\n",
        "print(inlgcdf[inlgcdf[\"Paper Type\"] == \"Short\"][\"stars\"].median())\n",
        "plt.hist(inlgcdf[inlgcdf[\"Paper Type\"] == \"Long\"][\"stars\"].apply(logone), bins=10, alpha=0.5, label='INLG Long Papers')\n",
        "plt.hist(inlgcdf[inlgcdf[\"Paper Type\"] == \"Short\"][\"stars\"].apply(logone), bins=10, alpha=0.5, label='INLG Short Papers')\n",
        "locs, _ = plt.xticks()\n",
        "plt.xticks(locs, [str(int(inv_logone(loc))) for loc in locs])\n",
        "plt.xlabel(\"GitHub Stars [log scale]\")\n",
        "plt.ylabel(\"# GitHub Repos in Bin\")\n",
        "plt.legend(loc='upper right')"
      ],
      "metadata": {
        "id": "6hwL9BK_GjiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(aclcdf[aclcdf[\"Paper Type\"] == \"Long\"][\"stars\"].mean())\n",
        "print(aclcdf[aclcdf[\"Paper Type\"] == \"Long\"][\"stars\"].median())\n",
        "print(aclcdf[aclcdf[\"Paper Type\"] == \"Short\"][\"stars\"].mean())\n",
        "print(aclcdf[aclcdf[\"Paper Type\"] == \"Short\"][\"stars\"].median())\n",
        "\n",
        "plt.hist(aclcdf[aclcdf[\"Paper Type\"] == \"Long\"][\"stars\"].apply(logone), bins=10, alpha=0.5, label='ACL Long Papers')\n",
        "plt.hist(aclcdf[aclcdf[\"Paper Type\"] == \"Short\"][\"stars\"].apply(logone), bins=10, alpha=0.5, label='ACL Short Papers')\n",
        "locs, _ = plt.xticks()\n",
        "plt.xticks(locs, [str(int(inv_logone(loc))) for loc in locs])\n",
        "plt.xlabel(\"GitHub Stars [log scale]\")\n",
        "plt.ylabel(\"# GitHub Repos in Bin\")\n",
        "plt.legend(loc='upper right', title=\"GitHub Stars\")"
      ],
      "metadata": {
        "id": "wU-L7_nKHjxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acl_stars_mean = aclcdf[\"stars\"].mean()\n",
        "inlg_stars_mean = inlgcdf[\"stars\"].mean()\n",
        "print(f\"mean acl {acl_stars_mean:.2f} vs ingl {inlg_stars_mean:.2f}\")\n",
        "acl_stars_q50 = aclcdf[\"stars\"].median()\n",
        "inlg_stars_q50 = inlgcdf[\"stars\"].median()\n",
        "print(f\"q50 acl {acl_stars_q50:.2f} vs ingl {inlg_stars_q50:.2f}\")\n",
        "\n",
        "aclcdf[\"stars\"].apply(logone).hist(bins=10, alpha=0.5, label=\"ACL\")\n",
        "inlgcdf[\"stars\"].apply(logone).hist(bins=10, alpha=0.5, label=\"INLG\")\n",
        "locs, _ = plt.xticks()\n",
        "plt.xticks(locs, [str(int(inv_logone(loc))) for loc in locs])\n",
        "plt.xlabel(\"GitHub Stars [log scale]\")\n",
        "plt.ylabel(\"# GitHub Repos in Bin\")\n",
        "plt.legend(loc='upper right', title=\"GitHub Stars for papers\")\n",
        "print(\"fig:stars_acl_inlg\")"
      ],
      "metadata": {
        "id": "G_zfp7AXNMrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet = GENERATION\n",
        "aidf = codedfs[sheet]\n",
        "\n",
        "acl_mispromised_industry_mean = aidf[(aidf[ACADEMIA_INDUSTRY] == \"Academia\") & aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\")][\"stars\"].mean()\n",
        "acl_mispromised_industry_q50 = aidf[(aidf[ACADEMIA_INDUSTRY] == \"Academia\") & aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\")][\"stars\"].median()\n",
        "\n",
        "print(f\"{acl_mispromised_industry_mean:.2f} {acl_mispromised_industry_q50:.2f}\")\n",
        "\n",
        "aidf[(aidf[ACADEMIA_INDUSTRY] == \"Academia\") & aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\")][\"stars\"].apply(logone).hist(bins=10, alpha=0.5, label=\"Mispromised in Academia\", color=\"orange\")\n",
        "aidf[(aidf[ACADEMIA_INDUSTRY] == \"Industry\") & aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\")][\"stars\"].apply(logone).hist(bins=10, alpha=0.5, label=\"Mispromised in Industry\", color='red')\n",
        "aidf[(aidf[LINK_TO_CODE] != NONE_FIRST_VIEW) & (~aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\"))][\"stars\"].apply(logone).hist(bins=10, alpha=0.2, label=\"Delivered\", color=\"grey\")\n",
        "plt.legend(loc='upper right', title=\"ACL GitHub Stars\" if sheet == GENERATION else \"INLG GitHub Stars\")\n",
        "locs, _ = plt.xticks()\n",
        "plt.xticks(locs, [str(int(inv_logone(loc))) for loc in locs])\n",
        "plt.xlabel(\"GitHub Stars [log scale]\")\n",
        "plt.ylabel(\"# GitHub Repos in Bin\")\n",
        "\n",
        "print(\"fig:stars_mispromised\")"
      ],
      "metadata": {
        "id": "G3R_-YwLS8gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet = INLG_2023_PAPERS\n",
        "aidf = codedfs[sheet]\n",
        "aidf[(aidf[ACADEMIA_INDUSTRY] == \"Academia\") & aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\")][\"stars\"].apply(logone).hist(bins=10, alpha=0.5, label=\"Mispromised in Academia\", color=\"orange\")\n",
        "aidf[(aidf[ACADEMIA_INDUSTRY] == \"Industry\") & aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\")][\"stars\"].apply(logone).hist(bins=10, alpha=0.5, label=\"Mispromised in Industry\", color='red')\n",
        "aidf[(aidf[LINK_TO_CODE] != NONE_FIRST_VIEW) & (~aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\"))][\"stars\"].apply(logone).hist(bins=10, alpha=0.2, label=\"Delivered\", color=\"grey\")\n",
        "plt.legend(loc='upper right', title=\"ACL GitHub Stars\" if sheet == GENERATION else \"INLG GitHub Stars\")\n",
        "locs, _ = plt.xticks()\n",
        "plt.xticks(locs, [str(int(inv_logone(loc))) for loc in locs])\n",
        "plt.xlabel(\"GitHub Stars [log scale]\")\n",
        "plt.ylabel(\"# GitHub Repos in Bin\")\n",
        "print(\"fig:stars_mispromised\")"
      ],
      "metadata": {
        "id": "Awmke3tpfgMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet = INLG_2023_PAPERS\n",
        "aidf = codedfs[sheet]\n",
        "aidf[(aidf[INSTALLATION] == \"None\")& (aidf[LINK_TO_CODE] != NONE_FIRST_VIEW) & (~aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\"))][\"stars\"].apply(logone).hist(bins=10, alpha=0.2, label=\"None Instruction\", color=\"grey\")\n",
        "aidf[(aidf[INSTALLATION] == \"Basic\")& (aidf[LINK_TO_CODE] != NONE_FIRST_VIEW) & (~aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\"))][\"stars\"].apply(logone).hist(bins=10, alpha=0.2, label=\"Basic Instruction\", color=\"red\")\n",
        "aidf[(aidf[INSTALLATION] == \"Detailed\")& (aidf[LINK_TO_CODE] != NONE_FIRST_VIEW) & (~aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\"))][\"stars\"].apply(logone).hist(bins=10, alpha=0.2, label=\"Detailed Instruction\", color=\"green\")\n",
        "plt.legend(loc='upper right', title=\"ACL GitHub Stars\" if sheet == GENERATION else \"INLG GitHub Stars\")\n",
        "locs, _ = plt.xticks()\n",
        "plt.xticks(locs, [str(int(inv_logone(loc))) for loc in locs])\n",
        "plt.xlabel(\"GitHub Stars [log scale]\")\n",
        "plt.ylabel(\"# GitHub Repos in Bin\")"
      ],
      "metadata": {
        "id": "FUDzHtn3getY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(len(codedfs), figsize=(10, 15))\n",
        "\n",
        "for sheet, ax in zip(codedfs, axs):\n",
        "  print(sheet)\n",
        "  aidf = codedfs[sheet]\n",
        "  # nocode_distribution_any_reason = aidf[aidf[LINK_TO_CODE] == NONE_FIRST_VIEW | aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\")][\"Academia/Industry\"].value_counts()\n",
        "  # nocode_distribution_any_reason.plot(kind='pie', autopct='%1.1f%%')\n",
        "\n",
        "  closed_source = aidf[aidf[LINK_TO_CODE] == NONE_FIRST_VIEW][ACADEMIA_INDUSTRY].sort_index().value_counts()\n",
        "  print(closed_source)\n",
        "  closed_source.plot(kind='pie', autopct='%1.1f%%', ax=ax)\n",
        "  ax.set_title(\"Closed Source at ACL by Institution Type\" if sheet == GENERATION else \"Closed Source at INLG by Institution Type\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"TODO make the colours the same for each label\")\n",
        "print(\"fig_mispromised_academia_vs_industry\")"
      ],
      "metadata": {
        "id": "NFzCuNNwFupd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(len(codedfs), figsize=(10, 15))\n",
        "\n",
        "for sheet, ax in zip(codedfs, axs):\n",
        "  print(sheet)\n",
        "  aidf = codedfs[sheet]\n",
        "  # nocode_distribution_any_reason = aidf[aidf[LINK_TO_CODE] == NONE_FIRST_VIEW | aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\")][\"Academia/Industry\"].value_counts()\n",
        "  # nocode_distribution_any_reason.plot(kind='pie', autopct='%1.1f%%')\n",
        "\n",
        "  mispromised_code = aidf[aidf[PROMISED_DELIVERED].str.startswith(\"NOT FILLED\")][ACADEMIA_INDUSTRY].sort_index().value_counts()\n",
        "  print(mispromised_code)\n",
        "  mispromised_code.plot(kind='bar', ax=ax)\n",
        "  msg = \"Promised Code but Not Published It at {conf}\"\n",
        "  ax.set_title(msg.format(conf=\"ACL\") if sheet == GENERATION else msg.format(conf=\"INLG\"))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"TODO make the colours the same for each label\")"
      ],
      "metadata": {
        "id": "BdotxD6DPMPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "counts = []  # accumulator for preprocess raw data LATER USED FOR PLOTTING GRAPHS format is tuple (Column Investigated, Conference name, Label, Label_count)"
      ],
      "metadata": {
        "id": "sca2BmWyDOQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = f\"Open Source?\"\n",
        "\n",
        "def mispromised(comment):\n",
        "    return \"Mispromised\" if comment.startswith('NOT FILLED') else \"Delivered\"\n",
        "\n",
        "for sheet in codedfs:\n",
        "    df = codedfs[sheet]\n",
        "    df[PROMISED_DELIVERED] = df[PROMISED_DELIVERED].fillna('None')\n",
        "    df['Category'] = df[PROMISED_DELIVERED].apply(mispromised)\n",
        "    mispromised_series = df['Category'].value_counts()\n",
        "    mispromised_series.plot(kind='pie', autopct='%1.1f%%')\n",
        "\n",
        "    dset = \"ACL\" if sheet == GENERATION else \"INLG\"\n",
        "    for k, v in mispromised_series.items():\n",
        "        counts.append((label, dset, k, v))\n",
        "\n",
        "    plt.title(f\"Mispromised to publish code:{sheet}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def classify_code(link):\n",
        "    if \"github\" in link:\n",
        "        return \"GitHub\"\n",
        "    elif link == NONE_FIRST_VIEW:\n",
        "        return \"None\"\n",
        "    else:\n",
        "        return \"Other\"\n",
        "\n",
        "for sheet in codedfs:\n",
        "    df = codedfs[sheet]\n",
        "    code_series = df[LINK_TO_CODE].apply(classify_code).value_counts()\n",
        "    code_series.plot(kind='pie', autopct='%1.1f%%')\n",
        "    plt.title(\"Code published at\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    dset = \"ACL\" if sheet == GENERATION else \"INLG\"\n",
        "    for k, v in code_series.items():\n",
        "        if k == \"None\":\n",
        "            counts.append((label, dset, \"Not Published\", v))\n",
        "\n",
        "\n",
        "print(\"fig_delivered_promised\")"
      ],
      "metadata": {
        "id": "A1aRQHGgCrN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = f\"Installation Instructions\"\n",
        "for sheet in codedfs:\n",
        "    df = codedfs[sheet]\n",
        "    df['Installation'] = df['Installation'].fillna('None')\n",
        "    print(f\"Unique values for 'Installation' in {sheet}: {df['Installation'].unique()}\")\n",
        "    installation_series = df['Installation'].value_counts()\n",
        "\n",
        "    dset = \"ACL\" if sheet == GENERATION else \"INLG\"\n",
        "    for k, v in installation_series.items():\n",
        "        counts.append((label, dset, k, v))\n",
        "\n",
        "    installation_series.plot(kind='pie', autopct='%1.1f%%')\n",
        "    plt.title(f\"'Installation' distribution in {sheet}\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"fig:install_instr\")"
      ],
      "metadata": {
        "id": "COQS3fIuCwqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = f\"Found Experiments\"\n",
        "for sheet in codedfs:\n",
        "    df = codedfs[sheet]\n",
        "    df['Experiments Covered'] = df['Experiments Covered'].fillna('None')\n",
        "    print(f\"Unique values for 'Experiments Covered' in {sheet}: {df['Experiments Covered'].unique()}\")\n",
        "    experiments_series = df['Experiments Covered'].value_counts()\n",
        "    experiments_series.plot(kind='pie', autopct='%1.1f%%')\n",
        "\n",
        "    dset = \"ACL\" if sheet == GENERATION else \"INLG\"\n",
        "    for k, v in experiments_series.items():\n",
        "        counts.append((label, dset, k, v))\n",
        "\n",
        "\n",
        "    plt.title(f\"'Experiments Covered' distribution in {sheet}\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"fig_experiments\")"
      ],
      "metadata": {
        "id": "maLTJ46yDiCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = f\"Documentation of Code\"\n",
        "\n",
        "for sheet in codedfs:\n",
        "    df = codedfs[sheet]\n",
        "    df['Scripts Documentation'] = df['Scripts Documentation'].fillna('None')\n",
        "    print(f\"Unique values for 'Scripts Documentation' in {sheet}: {df['Scripts Documentation'].unique()}\")\n",
        "    scripts_doc_series = df['Scripts Documentation'].value_counts().sort_index()\n",
        "    scripts_doc_series.plot(kind='pie', autopct='%1.1f%%')\n",
        "\n",
        "    dset = \"ACL\" if sheet == GENERATION else \"INLG\"\n",
        "    for k, v in scripts_doc_series.items():\n",
        "        counts.append((label, dset, k, v))\n",
        "    plt.title(f\"'Scripts Documentation' distribution in {sheet}\")\n",
        "    plt.show()\n",
        "    print(\"fig:documentation\")"
      ],
      "metadata": {
        "id": "Ko3LuUJhDqVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentage = True\n",
        "\n",
        "# see https://docs.google.com/spreadsheets/d/1NU6IlxhYg515RLjsVxNW5FS0ChWbIKi3yrrdfqEvsRM/edit#gid=1934821732\n",
        "INLG_PAPERS_NUM = 36\n",
        "ACL_PAPERS_NUM = 74\n",
        "\n",
        "\n",
        "plot_names = list(set(t[0] for t in counts))\n",
        "fig, axs = plt.subplots(len(plot_names), figsize=(10, 15))\n",
        "# TODO fix\n",
        "\n",
        "for i, (plot_name) in enumerate(plot_names):\n",
        "    for j, conf in enumerate(['ACL', 'INLG']):\n",
        "        names, cnts = zip(*[t[2:4] for t in counts if (t[0] == plot_name and t[1] == conf)])\n",
        "        axs[i].barh(names, cnts, label=conf)\n",
        "    axs[i].set_title(plot_name)\n",
        "    axs[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w4I7m1kRD8-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(set([t[0] for t in counts]))\n",
        "confs = [t[1] for t in counts]\n",
        "\n",
        "# fig, axs = plt.subplots(len(labels), figsize=(10, 15))\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "   d = {}\n",
        "   for conf in confs:\n",
        "      d[conf] = dict(t[2:4] for t in counts if t[1] == conf and t[0] == label)\n",
        "   comparison = pd.DataFrame(d).fillna(0).T\n",
        "\n",
        "\n",
        "   comparison_normalized = comparison.div(comparison.sum(axis=1), axis=0) * 100\n",
        "   ax = comparison_normalized.plot(kind='bar', stacked=True)\n",
        "\n",
        "   labels = list(d[confs[0]].keys())\n",
        "\n",
        "   plt.ylabel('Percentage')\n",
        "\n",
        "   # Shrink current axis's height by 10% on the bottom\n",
        "   box = ax.get_position()\n",
        "   ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
        "                  box.width, box.height * 0.9])\n",
        "\n",
        "   plt.legend(title=label, bbox_to_anchor=(0.5, -0.1), loc='upper center', labels=labels, ncols=2)\n",
        "   plt.xticks(rotation='horizontal')\n",
        "   plt.tight_layout()\n",
        "\n",
        "   # Annotate percentages on the bars\n",
        "   for p in ax.patches:\n",
        "      width, height = p.get_width(), p.get_height()\n",
        "      x, y = p.get_xy()\n",
        "      if height > 5:\n",
        "         ax.text(x + width / 2, y + height / 2, f'{height:.1f}%', ha='center', va='center')\n",
        "\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "04bfLGLYEQSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO For Code visualization -------------\n",
        "\n",
        "### Let's merge graph below with labels \"Implementation details provided\" and \"No Implementation details provided\" with the graph \"Documentation of Code\" just above"
      ],
      "metadata": {
        "id": "xdBpQdMtG8cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sheet names to analyze\n",
        "SHEETS = [\"INLG 2023\", \"ACL 2023\"]\n",
        "PROPERTIES = \"Metric properties\"\n",
        "\n",
        "# List the column names as constants to prevent typos\n",
        "ID = \"ACL Paper ID\"\n",
        "METRIC_NAME = \"Metric name\"\n",
        "NEWLY = \"Newly introduced?\"\n",
        "APPENDIX = \"Appendix\"\n",
        "TASK = \"Updated Task\"\n",
        "#TASK_OLD = \"Task\"\n",
        "#INK_TO_METRIC = \"Link to the Metric Paper\"\n",
        "#PAPER_LINK = \"Link to the Paper\"\n",
        "CORRELATED = \"Corrleated w/ Human Evaluation?\"\n",
        "ANNOTATOR = \"Annotator\"\n",
        "METRIC_IMPL = \"Metric Implementations\"\n",
        "IMPL = \"Metric Implementations\"\n",
        "RATIONALE = \"Notes: Rational\"\n",
        "COMMENTS = \"Comments\"\n",
        "CONF = \"Conf\"\n",
        "SURVEY = \"Survey\"\n",
        "FAMILY = \"Metric Family\"\n",
        "DISPLAY = 'Display Name'\n",
        "NORM = 'Normalized name'\n",
        "TRAIN = 'Trainable?'\n",
        "SRC = 'Uses source?'\n",
        "REF = 'Uses ref?'\n",
        "SRC_REF = 'Uses source or reference?'\n",
        "ADHOC = 'Is ad-hoc?'"
      ],
      "metadata": {
        "id": "IUpR5Yjx6azo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "# The following snippet checks for the number of annotations per one paper per annotator and reports discrepancies\n",
        "def print_metric_counts(df):\n",
        "  counts = df.groupby([ID, ANNOTATOR]).size().reset_index(name='count')\n",
        "  agreed = disagreed = 0\n",
        "  for i, group in counts.groupby(ID):\n",
        "      unique_counts = group['count'].nunique()\n",
        "      if unique_counts > 1:\n",
        "          disagreed += 1\n",
        "          annotations_info = []\n",
        "          for annotator, count in zip(group[ANNOTATOR], group['count']):\n",
        "              annotations_info.append(f\"{annotator} reported {count} metrics\")\n",
        "          print(f\"For paper id {i}, {'; '.join(annotations_info)}\")\n",
        "      else:\n",
        "        agreed += 1\n",
        "  print(f'With {agreed} agreements and {disagreed} disagreements, annotators agreed in {100 * agreed / float(agreed + disagreed)}% cases.')\n",
        "\n",
        "# Normalize the metric string\n",
        "def normalize_metric(metric):\n",
        "  metric = re.sub('[- +@]+', '', metric) # Remove spaces and other special symbols that might occur - keeping parentheses deliberately\n",
        "  metric = metric.lower() # Lowercase everything\n",
        "  metric = re.sub('(#survey|\\(corpus\\))', '', metric)\n",
        "  if metric in names_to_split.keys():\n",
        "    return names_to_split[metric]\n",
        "  if metric in metric_mapping.keys():\n",
        "    return metric_mapping[metric]\n",
        "  return metric\n",
        "\n",
        "# Some metrics were reported as several metrics in one line, split them to keep them consistent\n",
        "def split_grouped_metrics(df):\n",
        "  return df.explode(METRIC_NAME)\n",
        "\n",
        "def assign_family(metric):\n",
        "  if metric in metric_families.keys():\n",
        "    return metric_families[metric]\n",
        "  if 'human' in metric:\n",
        "    return 'Human'\n",
        "  return metric\n",
        "\n",
        "# Normalize URLs\n",
        "def normalize_urls(url):\n",
        "  return re.sub('(/|\\.pdf)$', '', url)\n",
        "\n",
        "def normalize_task(taskstring):\n",
        "  if taskstring is None:\n",
        "    return frozenset()\n",
        "  if isinstance(taskstring, frozenset):\n",
        "    return taskstring\n",
        "  subtasks = re.split('[:;,]', taskstring)\n",
        "  updated = []\n",
        "  for t in subtasks:\n",
        "    task = t.strip()\n",
        "    if task != \"\":\n",
        "      if task in task_mapping.keys():\n",
        "        task = task_mapping[task]\n",
        "      updated.append(task)\n",
        "\n",
        "  return frozenset(updated)"
      ],
      "metadata": {
        "id": "dXvAiUGb_IlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading\n",
        "Open the worksheet and make it into a DataFrame + Normalization"
      ],
      "metadata": {
        "id": "Q2tQssy2eOlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sheet2df(sheet):\n",
        "  worksheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1NU6IlxhYg515RLjsVxNW5FS0ChWbIKi3yrrdfqEvsRM/').worksheet(sheet)\n",
        "\n",
        "  # get_all_values gives a list of rows.\n",
        "  rows = worksheet.get_all_values()\n",
        "\n",
        "  # Convert to a DataFrame and render.\n",
        "  df = pd.DataFrame.from_records(rows[1:], columns=rows[0])\n",
        "  return df"
      ],
      "metadata": {
        "id": "3UIiWDyGoCDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading all the annotation data\n",
        "dfs = []\n",
        "for sheet in SHEETS:\n",
        "  df = sheet2df(sheet)\n",
        "  # Sometimes there will be blank rows with \"Updated Task\"\n",
        "  df = df[df[ID] != \"\"]\n",
        "  df[CONF] = sheet\n",
        "  df.reset_index(inplace=True, drop=True)\n",
        "  dfs.append(df)\n",
        "df = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "OpxEFlrjs3Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making paper URLs easy to get -- getting them from the other sheets\n",
        "papers_list = pd.concat([sheet2df('Generation')[['ACL ID', 'Paper Link']], sheet2df('INLG 2023 Papers')[['ACL ID', 'Paper Link']]], ignore_index=True)\n",
        "\n",
        "def id2link(paper_id):\n",
        "  try:\n",
        "    return list(papers_list[papers_list['ACL ID'] == paper_id]['Paper Link'])[0]\n",
        "  except:\n",
        "    return paper_id"
      ],
      "metadata": {
        "id": "Zna0K_vunvSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric name normalization"
      ],
      "metadata": {
        "id": "C6WUxwUvvSik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names_to_split = {\n",
        "    \"accuracy/p/r/f1\": [\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
        "    \"bleu{1,2}\": [\"bleu1\", \"bleu2\"],\n",
        "    \"distinctngrams(dist{1,2,3})\": ['distinctunigrams', 'distinctbigrams', 'distincttrigrams'],\n",
        "    \"dist{1,2,3}\": ['distinctunigrams', 'distinctbigrams', 'distincttrigrams'],\n",
        "    \"repnmetricsforn=2,3,4\": ['bigramrepetition', 'trigramrepetition', '4gramrepetition'],\n",
        "    \"rouge{1,2,l}\": [\"rouge1\", \"rouge2\", \"rougel\"],\n",
        "    \"rouge{1,2}\": [\"rouge1\", \"rouge2\"],\n",
        "    \"human(fluency,faithfulness,coverage,repetition)\": [\"human(fluency)\", \"human(faithfulness)\", \"human(coverage)\", \"human(repetition)\"],\n",
        "    \"human(fluency,relatedness,correctness,diversity)\": [\"human(fluency)\", \"human(relatedness)\", \"human(correctness)\", \"human(diversity)\"],\n",
        "    \"human(rationality,fluency)\": [\"human(rationality)\", \"human(fluency)\"],\n",
        "    \"human(simplicitiy,correctness,fluency)\": [\"human(simplicity)\", \"human(correctness)\", \"human(fluency)\"]\n",
        "}"
      ],
      "metadata": {
        "id": "wvjKK0Es-OPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_mapping = {\n",
        "    'harmonicmean(hmean)between(1−pbleu)andbleu': 'harmonicmean(pbleubleu)',\n",
        "    'harmonicmeanof1pbleuandbleu': 'harmonicmean(pbleubleu)',\n",
        "    'hmeanbetween(1pbleu)andbleu':'harmonicmean(pbleubleu)',\n",
        "    'harmonicmeanofbleu4andstyleaccuracy': 'harmonicmean(bleu4styleaccuracy)',\n",
        "    'pairwisebleu': 'pbleu',\n",
        "    'pbleu(selfbleu)': 'pbleu',\n",
        "    'em': 'exactmatch',\n",
        "    'exactmatch(em)': 'exactmatch',\n",
        "    'inform(rate)': 'inform',\n",
        "    'success(rate)': 'success',\n",
        "    'combinescore(informandrate)': 'combinedscore(informandrate)',\n",
        "    'bleu(4)': 'bleu4',\n",
        "    'accuracy(?)': 'accuracy',\n",
        "    'macroaveragedf1score(f1)': 'f1',\n",
        "    'sensitivity': 'demetrbenchmarksensitivityscores',\n",
        "    'bleurtbase': 'bleurt',\n",
        "    'allmpnetbasev2': 'mpnetcosinesimilarity',\n",
        "    'negmpnet': 'negmpnetcosinesimilarity',\n",
        "    'distinct1': 'distinctunigrams',\n",
        "    'distinct2': 'distinctbigrams',\n",
        "    'distinct4': 'distinct4grams',\n",
        "    'dist1': 'distinctunigrams',\n",
        "    'dist2': 'distinctbigrams',\n",
        "    'dist3': 'distincttrigrams',\n",
        "    'distinct3': 'distincttrigrams',\n",
        "    \"distn(4?)\": 'distinct4grams',\n",
        "    'bleuscore': 'bleu',\n",
        "    'corpusbleu': 'bleu',\n",
        "    'rquge': 'rouge',\n",
        "    'bertscorefscore': 'bertscoref1',\n",
        "    'bertscorep': 'bertscoreprecision',\n",
        "    'bertscorer': 'bertscorerecall',\n",
        "    'beatf1': 'bertscoref1',\n",
        "    'bertscorefmeasure': 'bertscoref1',\n",
        "    'bleurtscore': 'bleurt',\n",
        "    'human(creativeness)': 'human(creativity)',\n",
        "    'human(informativity)': 'human(informativeness)',\n",
        "    'grammar(gram)': 'grammaticality',\n",
        "    'human(intrestingness)': 'human(interesting)',\n",
        "    'human(overalquality/preference)': 'human(overall)',\n",
        "    'humanfluency': 'human(fluency)',\n",
        "    'humaninformativeness': 'human(informativeness)',\n",
        "    'lr(lexicalrepetition)': 'lexicalrepetition',\n",
        "    'mauvescore': 'mauve',\n",
        "    'rouge2(r2)': 'rouge',\n",
        "    'cosinedistance': 'cosinesimilarity',\n",
        "    'auroc': 'auc',\n",
        "    'detoxification': 'detoxify',\n",
        "    'fleschkincaidgradelevelreadability(fkgl)': 'fleschkincaidgradelevel',\n",
        "    'fkgl': 'fleschkincaidgradelevel',\n",
        "    'fleschkincaidgradelevel(fkgl)': 'fleschkincaidgradelevel',\n",
        "    'repeatedtrigrams': 'trigramrepetition'\n",
        "}"
      ],
      "metadata": {
        "id": "lTcwB4QF3nyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_mapping = {\n",
        "    \"natural language entailment)\": \"natural language inference\",\n",
        "    \"data-text generation\": \"data-to-text generation\",\n",
        "    \"data-to-text\": \"data-to-text generation\",\n",
        "    \"dialogue generation\": \"dialogue turn generation\",\n",
        "    \"dialogue response\": \"dialogue turn generation\",\n",
        "    \"dialouge\": \"dialogue turn generation\",\n",
        "    \"open-ended dialogue\": \"dialogue turn generation\",\n",
        "    \"task-oriented dialouge\": \"dialogue turn generation\",\n",
        "    \"paraphrase generation\": \"paraphrasing / lossless simplification\",\n",
        "    \"paraphrasing/lossless simplification\": \"paraphrasing / lossless simplification\",\n",
        "    \"text simplification\": \"compression / lossy simplification\",\n",
        "    \"question-generation\": \"question generation\",\n",
        "    \"quora question pairs\": \"question answering\",\n",
        "    \"and question answering\": \"question answering\",\n",
        "    \"simile generation\": \"simile generation (text-to-text)\",\n",
        "    \"story-generation\": \"story generation\",\n",
        "    \"text summarization\": \"summarisation (text-to-text)\",\n",
        "    \"summarisation\": \"summarisation (text-to-text)\",\n",
        "    \"summarization\": \"summarisation (text-to-text)\",\n",
        "    \"summarization (text-to-text)\": \"summarisation (text-to-text)\",\n",
        "    \"evaluate semantic diversity between two natural language \\ngeneration\": \"evaluate semantic diversity between two natural language generation\",\n",
        "    \"Updated Task\": \"\",\n",
        "    \"translation\": \"machine translation\",\n",
        "    \"surface realisation (slr to text)\": \"surface realisation (SLR to text)\"\n",
        "}"
      ],
      "metadata": {
        "id": "jnod6kamyAtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Metric Information from the Properties sheet\n",
        "def add_properties(df):\n",
        "  properties = sheet2df(PROPERTIES)\n",
        "  properties[ID] = properties['Paper IDs'].apply(lambda x: x.split())\n",
        "  properties = properties.explode(ID)\n",
        "  df = df.merge(properties, left_on=[METRIC_NAME, ID], right_on=[METRIC_NAME, ID], how='left')\n",
        "  return df"
      ],
      "metadata": {
        "id": "k9O0NAdnfONS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "df[SURVEY] = df[METRIC_NAME].str.contains(\"#survey\")\n",
        "df[METRIC_NAME] = df[METRIC_NAME].apply(normalize_metric)\n",
        "df[TASK] = df[TASK].apply(normalize_task)\n",
        "df = split_grouped_metrics(df)\n",
        "\n",
        "df = add_properties(df)\n",
        "df[FAMILY] = df[FAMILY].fillna(\"Human\")\n",
        "df = df.fillna('')\n",
        "\n",
        "# Leaving the surveys out of the analysis\n",
        "df = df[df[SURVEY] == False]"
      ],
      "metadata": {
        "id": "ksciZvly8_px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get rid of some small categories\n",
        "print(f\"There are {len(df[df[CORRELATED] == 'Correlation with previous human eval'])} metrics with a correlation to previous human eval\")\n",
        "df = df.replace(\"Correlation with previous human eval\", \"Human evaluation, quantitative correlation\")\n",
        "\n",
        "\n",
        "# First take a look at papers with no metrics at all\n",
        "no_metrics = df[df[METRIC_NAME] == \"\"]\n",
        "num_no_metrics = len(no_metrics[ID].unique())\n",
        "df_all = df[df[METRIC_NAME] != \"\"]\n",
        "num_with_all = len(df_all[ID].unique())\n",
        "print(f\"There are {num_no_metrics} papers with no metrics, {num_with_all} papers remain for analysis.\")\n",
        "\n",
        "\n",
        "# Now exclude papers with only human metrics, but also report how many papers uses human metrics\n",
        "hum_df = df[df[METRIC_NAME].str.contains('human')]\n",
        "papers_hum = len(hum_df[ID].unique())\n",
        "num_h = len(hum_df)\n",
        "dist_h = len(hum_df[METRIC_NAME].unique())\n",
        "print(f\"{papers_hum} out of {len(df[ID].unique())} papers use human evaluation. In total, there were {num_h} instances of human metrics used, {dist_h} of those are unique.\")\n",
        "\n",
        "auto_df = df_all[~df_all[METRIC_NAME].str.contains('human')]\n",
        "papers_auto = len(auto_df[ID].unique())\n",
        "num_a = len(auto_df)\n",
        "dist_a = len(auto_df[METRIC_NAME].unique())\n",
        "print(f\"{papers_auto} out of {len(df[ID].unique())} papers use automatic evaluation. In total, there were {num_a} instances of automatic metrics used, {dist_a} of those are unique.\")\n",
        "\n",
        "num_fam = len(auto_df[FAMILY].unique())\n",
        "print(f\"There are {num_fam} metric families.\")"
      ],
      "metadata": {
        "id": "al0Hi9ur6j8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many papers contain both human and automatic metrics:\n",
        "hum_paper_ids = hum_df[ID].unique().tolist()\n",
        "auto_paper_ids = auto_df[ID].unique().tolist()\n",
        "print(f\"Number of papers that have both automatic and human evaluations: {len(set(auto_paper_ids).intersection(set(hum_paper_ids)))}\")"
      ],
      "metadata": {
        "id": "GISeT7jsWodS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For debugging the metric families\n",
        "by_family = {}\n",
        "for entry in df[[ID, NEWLY, METRIC_NAME,FAMILY]].to_dict('records'):\n",
        "  by_family[entry[FAMILY]] = by_family.get(entry[FAMILY], [])\n",
        "  by_family[entry[FAMILY]].append({METRIC_NAME: entry[METRIC_NAME], ID: entry[ID], 'URL': id2link(entry[ID]), NEWLY: entry[NEWLY]})"
      ],
      "metadata": {
        "id": "JATEklD5hw3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the code that produced the base of the \"Metric properties\" sheet\n",
        "import csv\n",
        "\n",
        "data_rows = []\n",
        "\n",
        "for key, values in by_family.items():\n",
        "  metric_names = {}\n",
        "  # We only care about automatic metrics in this part\n",
        "  if key == \"Human\":\n",
        "    continue\n",
        "  for value in values:\n",
        "    # Multiple occurrences of the same metric: just add IDs & URLs to the 1st mention\n",
        "    if value[METRIC_NAME] in metric_names:\n",
        "      data_rows[metric_names[value[METRIC_NAME]]][-3] += 1\n",
        "      data_rows[metric_names[value[METRIC_NAME]]][-2] += ' ' + value[ID]\n",
        "      data_rows[metric_names[value[METRIC_NAME]]][-1] += ' ' + value['URL']\n",
        "      continue\n",
        "    # 1st occurrence: create a new row\n",
        "    row = [value[METRIC_NAME], key, None, None, None, None, 1, value[ID], value['URL']]\n",
        "    metric_names[value[METRIC_NAME]] = len(data_rows)  # store ref to row where it's introduced\n",
        "    data_rows.append(row)\n",
        "\n",
        "with open('dict.csv', 'w') as csv_file:\n",
        "    writer = csv.writer(csv_file, delimiter='\\t')\n",
        "    for row in data_rows:\n",
        "      writer.writerow(row)"
      ],
      "metadata": {
        "id": "LQEgyZ6IM8VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OD: what does this do ?\n",
        "# PS is commenting this out because it makes the notebook crash\n",
        "#families = set(metric_families.values())\n",
        "#print(sorted(set(df[FAMILY].unique()).difference(families)))"
      ],
      "metadata": {
        "id": "ItfzwRL5D6kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uni = set ()\n",
        "for fs in df[TASK].unique():\n",
        "  uni.update(fs)\n",
        "uni"
      ],
      "metadata": {
        "id": "QtSDqyKo4EGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defined_tasks = {'data-to-text generation',\n",
        "'dialogue turn generation',\n",
        "'content selection/determination',\n",
        "'content ordering/structuring',\n",
        "'deep generation (DLR to text)',\n",
        "'aggregation',\n",
        "'lexicalisation',\n",
        "'referring expression generation',\n",
        "'surface realisation (SLR to text)',\n",
        "'feature-controlled generation',\n",
        "'question generation',\n",
        "'question answering',\n",
        "'paraphrasing / lossless simplification',\n",
        "'machine translation',\n",
        "'summarisation (text-to-text)',\n",
        "'compression / lossy simplification',\n",
        "'end-to-end text generation',\n",
        "'multiple (list all)',\n",
        "'other (please specify)'}"
      ],
      "metadata": {
        "id": "DGar75G8fncw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "other = uni.difference(defined_tasks)"
      ],
      "metadata": {
        "id": "Nmm1nIb-f6Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_df = df.copy(deep=True)\n",
        "task_df[TASK] = task_df[TASK].apply(lambda x: list(x))\n",
        "task_df = task_df.explode(TASK).drop_duplicates(subset=[ID, TASK])\n",
        "other_tasks = task_df[task_df[TASK].isin(other)]\n",
        "other_tasks[TASK].value_counts()"
      ],
      "metadata": {
        "id": "lxMn4yVgg7En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "other_tasks[other_tasks[TASK] == \"open-ended text generation (LM sampling)\"][['Annotator_x', ID, TASK, 'Link to the Paper']]"
      ],
      "metadata": {
        "id": "e25GN4idiyoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_df[TASK].value_counts()"
      ],
      "metadata": {
        "id": "axeuFLnbkY9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stats computation"
      ],
      "metadata": {
        "id": "WM_GVoTYveVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#xx: trying to beautify venn diagram\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib_venn import venn2\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5), facecolor='none')\n",
        "\n",
        "\n",
        "# ACL 2023 Venn diagram\n",
        "axs[0].set_title(\"ACL 2023\")\n",
        "venn_acl = venn2(\n",
        "    subsets=(\n",
        "        set(hum_df[hum_df[CONF] == \"ACL 2023\"][ID].unique()),\n",
        "        set(auto_df[auto_df[CONF] == \"ACL 2023\"][ID].unique())\n",
        "    ),\n",
        "    set_labels=[\"Human Evaluation\", \"Automatic Evaluation\"],\n",
        "    set_colors=(\"#A682FF\", \"#55C1FF\"),\n",
        "    ax=axs[0]\n",
        ")\n",
        "\n",
        "#Setting the dashed line for perimeter\n",
        "for circle in venn_acl.patches:\n",
        "    if circle:\n",
        "        circle.set_edgecolor('black')\n",
        "        circle.set_linestyle('--')\n",
        "\n",
        "#manually aligning labels and titles\n",
        "venn_acl.set_labels[0].set(x=-0.2, y=-0.6)\n",
        "venn_acl.set_labels[1].set(x=0.2, y=-0.6)\n",
        "axs[0].set_title(\"ACL 2023\", x=0.5, y=1)\n",
        "\n",
        "# INLG 2023 Venn diagram\n",
        "axs[1].set_title(\"INLG 2023\")\n",
        "venn_inlg =venn2(\n",
        "    subsets=(\n",
        "        set(hum_df[hum_df[CONF] == \"INLG 2023\"][ID].unique()),\n",
        "        set(auto_df[auto_df[CONF] == \"INLG 2023\"][ID].unique())\n",
        "    ),\n",
        "    set_labels=[\"Human Evaluation\", \"Automatic Evaluation\"],\n",
        "    set_colors=(\"#D00000\", \"#FFBA08\"),\n",
        "    ax=axs[1]\n",
        ")\n",
        "\n",
        "#Setting the dashed line for perimeter\n",
        "for circle in venn_inlg.patches:\n",
        "    if circle:\n",
        "        circle.set_edgecolor('black')\n",
        "        circle.set_linestyle('--')\n",
        "axs[1].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "axs[1].patch.set_alpha(0)\n",
        "\n",
        "#manually aligning labels and titles\n",
        "venn_inlg.set_labels[0].set(x=-0.2, y=-0.62)\n",
        "venn_inlg.set_labels[1].set(x=0.16, y=-0.62)\n",
        "axs[1].set_title(\"INLG 2023\", x=0.5, y=1.04)\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "T4DLxqDdGQgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_df[FAMILY].value_counts().plot(kind='barh', figsize=(8, 10))"
      ],
      "metadata": {
        "id": "sBBLTB0MF493"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#xx: trying to visualise metric family usage as a double spider plot\n",
        "\n",
        "def plot_spider_chart_overlay_sorted_with_values(df1, df2, ax, title=''):\n",
        "    nl = '\\n' # Placeholder for f-strings\n",
        "\n",
        "    # Combine unique family values from both DataFrames\n",
        "    unique_values = np.union1d(df1['Metric Family'].unique(), df2['Metric Family'].unique())\n",
        "\n",
        "    # Count occurrences of each family value for both DataFrames\n",
        "    counts_df1 = df1['Metric Family'].value_counts().reindex(unique_values, fill_value=0)\n",
        "    counts_df2 = df2['Metric Family'].value_counts().reindex(unique_values, fill_value=0)\n",
        "\n",
        "    # Sort family values based on counts in df1\n",
        "    sorted_values = counts_df1.sort_values(ascending=False).index\n",
        "\n",
        "    # Reindex counts based on sorted family values\n",
        "    counts_df1_sorted = counts_df1.reindex(sorted_values)\n",
        "    counts_df2_sorted = counts_df2.reindex(sorted_values)\n",
        "\n",
        "    # Prepare data for radial bar chart\n",
        "    labels = sorted_values\n",
        "    values_df1 = counts_df1_sorted.values\n",
        "    values_df2 = counts_df2_sorted.values\n",
        "    num_vars = len(labels)\n",
        "\n",
        "    # Compute angle for each bar\n",
        "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
        "\n",
        "    # The plot is circular, so we need to \"complete the loop\"\n",
        "    values_df1 = np.concatenate((values_df1, [values_df1[0]]))\n",
        "    values_df2 = np.concatenate((values_df2, [values_df2[0]]))\n",
        "    angles += angles[:1]\n",
        "\n",
        "    # Define the radial distance factor for labels\n",
        "    radial_distance_factor = 1.3\n",
        "\n",
        "    # Use seaborn style\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Calculate rotation angle for labels\n",
        "    rotation_angle = np.degrees(angles)\n",
        "\n",
        "    # Draw one axe per variable and add labels and values on top of spikes\n",
        "    for angle, label, rotation, value_df1, value_df2 in zip(angles, labels, rotation_angle, values_df1, values_df2):\n",
        "        # Split label text into words\n",
        "        words = label.split()\n",
        "        if len(words) > 4:\n",
        "            label =  f'{\" \".join(words[:3])}{nl}{\" \".join(words[3:])}'  # Insert line break if more than 3 words\n",
        "        radial_pos = max(max(values_df1), max(values_df2)) * radial_distance_factor\n",
        "        if rotation > 90 and rotation <= 270:\n",
        "            rotation += 180  # Add 180 degrees to rotate labels in the lower half\n",
        "        ax.text(angle, radial_pos, f'{label}', size=10, horizontalalignment='center',\n",
        "                verticalalignment='center', rotation=rotation, rotation_mode='anchor')\n",
        "        ax.text(angle, radial_pos*0.6, f'{value_df1} - {value_df2}', size=9,\n",
        "                horizontalalignment='center', verticalalignment='center', rotation=rotation, rotation_mode='anchor')\n",
        "\n",
        "    # Draw ylabels without degrees\n",
        "    ax.set_rlabel_position(0)\n",
        "    ax.set_yticks([max(max(values_df1), max(values_df2))/4, max(max(values_df1), max(values_df2))/2,\n",
        "                   3*max(max(values_df1), max(values_df2))/4, max(max(values_df1), max(values_df2))],\n",
        "                   [str(int(max(max(values_df1), max(values_df2))/4)),\n",
        "                    str(int(max(max(values_df1), max(values_df2))/2)),\n",
        "                    str(int(3*max(max(values_df1), max(values_df2))/4)),\n",
        "                    str(int(max(max(values_df1), max(values_df2))))], color=\"grey\", size=12)\n",
        "\n",
        "    # Remove y-axis labels\n",
        "    ax.set_yticklabels([]) # Remove ref values on the first ranked metric family\n",
        "    ax.set_xticklabels([]) # Remove degree marks\n",
        "    ax.set_ylim([0,39])\n",
        "    plt.yticks([0,20,40])\n",
        "\n",
        "    # Plot data for df1\n",
        "    ax.plot(angles, values_df1, linewidth=1, linestyle='solid', label='INLG 2023')\n",
        "    ax.fill(angles, values_df1, 'b', alpha=0.1)\n",
        "\n",
        "    # Plot data for df2\n",
        "    ax.plot(angles, values_df2, linewidth=1, linestyle='solid', label='ACL 2023')\n",
        "    ax.fill(angles, values_df2, 'r', alpha=0.1)\n",
        "\n",
        "    # Title\n",
        "    ax.set_title(title, size=18, y=1.1)\n",
        "    ax.legend(loc='upper right', title=\"Venue\", bbox_to_anchor=(1.5, 0.5))\n",
        "\n",
        "df1 = auto_df[auto_df[CONF] == \"INLG 2023\"].drop_duplicates(subset=[ID, FAMILY])\n",
        "df2 = auto_df[auto_df[CONF] == \"ACL 2023\"].drop_duplicates(subset=[ID, FAMILY])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 7), subplot_kw=dict(polar=True))\n",
        "plot_spider_chart_overlay_sorted_with_values(df1, df2, ax, title='Metric families usage across venues\\n\\n\\n\\n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fNjW8V1ykjnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xx wanted a graph of the high level families, recomment if necessary\n",
        "#F = \"Metric family\"\n",
        "F = \"MF2\"\n",
        "\n",
        "#xx: showing metric families as a grouped bar chart, only top-10 metrics (ranked from INLG) shown\n",
        "def plot_bar_chart_overlay_sorted_with_values(df1, df2, ax, title='', color1='blue', color2='red'):\n",
        "    # Use seaborn style\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Combine unique \"Metric Family\" values from both DataFrames\n",
        "    unique_values = np.union1d(df1[F].unique(), df2[F].unique())\n",
        "\n",
        "    # Count occurrences of each value in 'Metric Family' column for both DataFrames\n",
        "    counts_df1 = df1[F].value_counts().reindex(unique_values, fill_value=0)\n",
        "    counts_df2 = df2[F].value_counts().reindex(unique_values, fill_value=0)\n",
        "\n",
        "    # Sort \"Metric Family\" values based on counts in df1 and get the top 10\n",
        "    top_10_values = counts_df1.sort_values(ascending=False).head(10).index\n",
        "\n",
        "    # Sum up all other values into 'Other' category\n",
        "    other_count_df1 = counts_df1[~counts_df1.index.isin(top_10_values)].sum()\n",
        "    other_count_df2 = counts_df2[~counts_df2.index.isin(top_10_values)].sum()\n",
        "\n",
        "    # Add 'Other' category to the top 10 values\n",
        "    top_10_values = top_10_values.append(pd.Index(['Other']))\n",
        "\n",
        "    # Reindex counts based on top 10 \"Metric Family\" values plus 'Other'\n",
        "    counts_df1_sorted = pd.concat([counts_df1.reindex(top_10_values[:-1]), pd.Series({'Other': other_count_df1})])\n",
        "    counts_df2_sorted = pd.concat([counts_df2.reindex(top_10_values[:-1]), pd.Series({'Other': other_count_df2})])\n",
        "\n",
        "    # Convert counts to percentages\n",
        "    values_df1 = (counts_df1_sorted / counts_df1.sum() * 100).values\n",
        "    values_df2 = (counts_df2_sorted / counts_df2.sum() * 100).values\n",
        "    labels = top_10_values\n",
        "\n",
        "    x = np.arange(len(labels))  # the label locations\n",
        "    width = 0.35  # the width of the bars\n",
        "\n",
        "    # Plot data for df1 and df2\n",
        "    rects1 = ax.bar(x - width/2, values_df1, width, label='INLG 2023', color=color1, alpha=1)\n",
        "    rects2 = ax.bar(x + width/2, values_df2, width, label='ACL 2023', color=color2, alpha=1)\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylabel('Percentage (%)')\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels, rotation=90)\n",
        "    ax.legend(loc='upper center')\n",
        "\n",
        "    # Attach a text label above each bar in *rects*, displaying its height.\n",
        "    def autolabel(rects):\n",
        "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "        for rect in rects:\n",
        "            height = rect.get_height()\n",
        "            ax.annotate(f'{height:.1f}%',\n",
        "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom',\n",
        "                        size=8)\n",
        "\n",
        "    autolabel(rects1)\n",
        "    autolabel(rects2)\n",
        "# Assuming df1 and df2 are your two DataFrames\n",
        "df1 = auto_df[auto_df[CONF] == \"INLG 2023\"].drop_duplicates(subset=[ID, FAMILY])\n",
        "df2 = auto_df[auto_df[CONF] == \"ACL 2023\"].drop_duplicates(subset=[ID, FAMILY])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "plot_bar_chart_overlay_sorted_with_values(df1, df2, ax, title='Metric families usage across venues', color1='#bbe6ff',color2='#ec9999')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XqtdRYV1k3HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For XX: fancy bar chart about metric\n",
        "\n",
        "IMPORTANT: the first 4 cells are preparatory for the actual chart. This is a very hacky chart, so the final cell may print multiple stuff before the actual chat (which you will recognise). Don't touch anything but the last cell!"
      ],
      "metadata": {
        "id": "H4A6pa-lEVWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'Metric Family', 'MF2', 'Task'\n",
        "var = 'MF2'"
      ],
      "metadata": {
        "id": "7-Tnp-odESKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from sys import exit\n",
        "\n",
        "# Filter the dataframes based on the given conditions\n",
        "df1 = auto_df[auto_df[CONF] == 'INLG 2023'].drop_duplicates(subset=[ID, FAMILY])\n",
        "\n",
        "# Sort df1 and df2 based on the count of var\n",
        "df1_sorted = df1.sort_values(by=var)\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 6))\n",
        "\n",
        "# Plot bar plot for df1\n",
        "df1_sorted[var].value_counts().plot(kind='bar', ax=axes, position=0, width=0.4)\n",
        "axes.set_xlabel(var)\n",
        "axes.set_ylabel('Count')\n",
        "axes.set_title('Grouped Bar Plot')\n",
        "axes.legend(['INLG 2023', 'ACL 2023'])\n",
        "\n",
        "# Get the current tick labels\n",
        "print(plt.xticks()[1])\n",
        "inlg_labels = copy.deepcopy(plt.xticks()[1])\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "DFdDkug8Ew27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter the dataframes based on the given conditions\n",
        "df2 = auto_df[auto_df[CONF] == 'ACL 2023'].drop_duplicates(subset=[ID, FAMILY])\n",
        "\n",
        "# Sort df1 and df2 based on the count of var\n",
        "df2_sorted = df2.sort_values(by=var)\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 6))\n",
        "\n",
        "# Plot bar plot for df2, adjust the positions of the bars\n",
        "df2_sorted[var].value_counts().plot(kind='bar', ax=axes, position=1, width=0.4)\n",
        "print(plt.xticks()[1])\n",
        "acl_labels = copy.deepcopy(plt.xticks()[1])\n",
        "plt.clf()"
      ],
      "metadata": {
        "id": "iu9J4yIqE10H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qhr643pecPtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is a sanity check\n",
        "print(inlg_labels)\n",
        "print(acl_labels)"
      ],
      "metadata": {
        "id": "2b5pdGjVExA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# Cause even my prints must be aestethic\n",
        "yellow = '\\033[93m'\n",
        "green = '\\033[92m'\n",
        "red = '\\033[91m'\n",
        "blue = '\\033[94m'\n",
        "pink = '\\033[95m'\n",
        "reset = '\\033[0m'\n",
        "\n",
        "limit = 1\n",
        "if limit > 0:\n",
        "  print(f'{yellow}> WARNING: PLOTTING ONLY THE FIRST {limit} elements of the series {reset}')\n",
        "\n",
        "#for venue-level coloring\n",
        "inlg_color_single='#bbe6ff'\n",
        "acl_color_single='#ec9999'\n",
        "\n",
        "# For metric-level coloring\n",
        "inlg_colors_list = [\"#03045e\",\"#023e8a\",\"#0077b6\",\"#0096c7\",\"#00b4d8\",\"#48cae4\",\"#90e0ef\",\"#ade8f4\",\"#caf0f8\"]\n",
        "acl_colors_list = [\"#03071e\",\"#370617\",\"#6a040f\",\"#9d0208\",\"#d00000\",\"#dc2f02\",\"#e85d04\",\"#f48c06\",\"#faa307\",\"#ffba08\"]\n",
        "\n",
        "#choose your favourite pattern\n",
        "patterns = [ \"/\" , \"\\\\\" , \"|\" , \"-\" , \"+\" , \"x\", \"o\", \"O\", \".\", \"*\" ]\n",
        "#to make the pattern more subtle\n",
        "plt.rcParams['hatch.linewidth'] = 0.1  # originally 1.0\n",
        "\n",
        "\n",
        "# Filter the dataframes based on the given conditions\n",
        "df1 = auto_df[auto_df[CONF] == 'INLG 2023'].drop_duplicates(subset=[ID, FAMILY])\n",
        "df2 = auto_df[auto_df[CONF] == 'ACL 2023'].drop_duplicates(subset=[ID, FAMILY])\n",
        "\n",
        "# Sort both venues by count\n",
        "df1_sorted = df1.sort_values(by=var)\n",
        "df2_sorted = df2.sort_values(by=var)\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12, 6))\n",
        "\n",
        "# Plot bar plot for df1\n",
        "# IMPORTANT 1: Remember to update the color/s variable\n",
        "# IMPORTANT 2: You can make the pattern more or less dense by multiplying it for a given number\n",
        "\n",
        "if limit > 0:\n",
        "  df1_bar = df1_sorted[var].value_counts()[:limit].plot(kind='bar', color=inlg_colors_list, ax=axes, position=0,  width=0.45, hatch=patterns[5]*3, alpha = 0.8)\n",
        "else:\n",
        "  df1_bar = df1_sorted[var].value_counts().plot(kind='bar', color=inlg_colors_list, ax=axes, position=0,  width=0.45, hatch=patterns[5]*3, alpha = 0.8)\n",
        "\n",
        "# Setting various params\n",
        "axes.set_xlabel(var)\n",
        "axes.set_ylabel('Count')\n",
        "axes.set_title(f'{var} per venue')\n",
        "axes.legend(['INLG 2023', 'ACL 2023'])\n",
        "\n",
        "# Plot bar plot for df2, then adjust the positions of the bars to create an overlay\n",
        "# IMPORTANT 1: Remember to update the color/s variable\n",
        "# IMPORTANT 2: You can make the pattern more or less dense by multiplying it for a given number\n",
        "if limit > 0:\n",
        "  df2_bar = df2_sorted[var].value_counts()[:limit].plot(kind='bar', color=acl_colors_list, ax=axes, position=1,  width=0.45, hatch=patterns[6]*3, alpha=0.8)\n",
        "else:\n",
        "  df2_bar = df2_sorted[var].value_counts().plot(kind='bar', color=acl_colors_list, ax=axes, position=1,  width=0.45, hatch=patterns[6]*3, alpha=0.8)\n",
        "\n",
        "\n",
        "# It turns out that INLG and ACL have different amount of metrics, so we need to make them equal (a.k.a extending the shortest one with empty values)\n",
        "def expand_lists(list1, list2):\n",
        "    if len(list1) < len(list2):\n",
        "        while len(list1) < len(list2):\n",
        "            list1.append(plt.Text(0, len(list1), ''))\n",
        "    elif len(list2) < len(list1):\n",
        "        while len(list2) < len(list1):\n",
        "            list2.append(plt.Text(0, len(list2), ''))\n",
        "    return list1, list2\n",
        "\n",
        "if limit > 0:\n",
        "  inlg_labels = inlg_labels[:limit]\n",
        "  acl_labels = acl_labels[:limit]\n",
        "inlg_labels, acl_labels = expand_lists(inlg_labels, acl_labels)\n",
        "\n",
        "# shifting labels, needs manual setting by trials\n",
        "# for metric family = 0.18, 0.4\n",
        "shift_1 = 0.18\n",
        "shift_2 = 0.4\n",
        "\n",
        "# Get the current tick positions and labels\n",
        "current_positions = plt.xticks()[0]\n",
        "current_positions = [pos - shift_1 for pos in current_positions]\n",
        "current_labels = acl_labels\n",
        "\n",
        "print(f'{yellow}> WARNING: These two numbers should be equal: {len(inlg_labels)}=={len(acl_labels)}')\n",
        "print(f'{yellow}> If they are not, ACL contains more metrics/families/whatever than INLG or vice-versa and you should manually adjust.')\n",
        "\n",
        "\n",
        "# Calculate new tick positions for the additional set of labels\n",
        "additional_positions = [pos + shift_2 for pos in current_positions]\n",
        "\n",
        "# Combine original and additional labels and positions\n",
        "combined_labels = list(current_labels) + inlg_labels\n",
        "combined_positions = list(current_positions) + additional_positions\n",
        "\n",
        "# Set the combined tick positions and labels\n",
        "plt.xticks(combined_positions, combined_labels, size = 10)\n",
        "\n",
        "# X axis limits, again needs to be manually adjusted for each measure\n",
        "if limit>0:\n",
        "  raise Warning('Hello')\n",
        "  plt.xlim(-0.45,9.5)\n",
        "\n",
        "raise Warning('Hello')\n",
        "\n",
        "\n",
        "#plt.legend(loc='upper right', labels=['INLG 2023', 'ACL 2023']) #old legend\n",
        "# Custom legend cause I do what I want\n",
        "legend_elements = [Patch(facecolor='orange', label='Family 1'),\n",
        "                   Patch(facecolor='orange', label='Family 2'),\n",
        "                   Patch(facecolor='orange', label='Family 3'),\n",
        "                   Patch(facecolor='orange', label='Family 4'),\n",
        "                   Patch(facecolor='orange', label='Need more? Need other colors?')]\n",
        "\n",
        "# Create the figure\n",
        "axes.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M21EUu-DEw9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XX's scratchpad"
      ],
      "metadata": {
        "id": "1a5DDDSik8PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Filter the dataframes based on the given conditions\n",
        "df1 = auto_df[auto_df[CONF] == 'INLG 2023'].drop_duplicates(subset=[ID, FAMILY])\n",
        "df2 = auto_df[auto_df[CONF] == 'ACL 2023'].drop_duplicates(subset=[ID, FAMILY])\n",
        "\n",
        "df1_dict = df1[[FAMILY, 'MF2']].value_counts().to_dict()\n",
        "df2_dict = df2[[FAMILY, 'MF2']].value_counts().to_dict()\n",
        "# summed = dict(Counter(df1_dict) + Counter(df2_dict))\n",
        "# make the sorting normalized\n",
        "summed = dict(Counter((df1[[FAMILY, 'MF2']].value_counts() / len(df1)).to_dict()) + Counter((df2[[FAMILY, 'MF2']].value_counts() / len(df2)).to_dict()))\n",
        "\n",
        "hlf_counts = {hlf: sum({v for k, v in summed.items() if k[1] == hlf}) for hlf in {k[1] for k in summed}}\n",
        "# high-level families sorted by total frequency\n",
        "hlf_list = sorted(hlf_counts.keys(), key=lambda k: hlf_counts[k], reverse=True)"
      ],
      "metadata": {
        "id": "jAofKwt1gSkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hierarchical: hlf -> family\n",
        "def get_hier_data(df_dict):\n",
        "  hier = {}\n",
        "  for k in summed:\n",
        "    hier[k[1]] = hier.get(k[1], {})\n",
        "    hier[k[1]][k[0]] = df_dict.get(k, 0)\n",
        "  maxlen = max(len(v) for v in hier.values())\n",
        "\n",
        "  vals = [[] for _ in range(maxlen)]\n",
        "  labels = [[] for _ in range(maxlen)]\n",
        "  for hlf in hlf_list:\n",
        "      g = list(sorted(hier[hlf].items(), key=lambda i: i[1], reverse=True))\n",
        "      g += [('', 0)] * (maxlen - len(g))\n",
        "      for i, (k, v) in enumerate(g):\n",
        "          labels[i].append(f'{hlf}-{k}' if k else '')\n",
        "          vals[i].append(v)\n",
        "  return vals, labels\n",
        "\n",
        "df1_hier = get_hier_data(df1_dict)\n",
        "df2_hier = get_hier_data(df2_dict)"
      ],
      "metadata": {
        "id": "yR-vhw6WYJvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "\n",
        "#for venue-level coloring\n",
        "inlg_color_single='#bbe6ff'\n",
        "acl_color_single='#ec9999'\n",
        "\n",
        "\n",
        "#choose your favourite pattern\n",
        "patterns = [ None, \"////\" , \"\\\\\\\\\\\\\\\\\" , \"||||\" , \"----\" , \"++++\" , \"xxxx\", \"....\", \"oooo\", \"****\", \"OOOO\" ]\n",
        "#to make the pattern more subtle\n",
        "plt.rcParams['hatch.linewidth'] = 1 # 0.1  # originally 1.0\n",
        "\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(12, 6))\n",
        "\n",
        "def create_barplot(hlf_list, data, labels, dflen, color, hatch, pos):\n",
        "\n",
        "  bottoms = np.zeros(len(hlf_list))\n",
        "  for ds, ls, h in zip(data, labels, patterns):\n",
        "    ds = np.array(ds) / dflen * 100  # percentage\n",
        "    axes.bar(np.arange(len(hlf_list)) - 0.15 + 0.3 * pos,\n",
        "             ds,\n",
        "             color=mf_colors,\n",
        "             # position=pos,\n",
        "             width=0.3,\n",
        "             hatch=h,\n",
        "             label=ls,\n",
        "             bottom=bottoms,\n",
        "             alpha=1 - 0.4 * pos)\n",
        "    bottoms += ds\n",
        "\n",
        "# Plot bar plot for df1\n",
        "# IMPORTANT 1: Remember to update the color/s variable\n",
        "# IMPORTANT 2: You can make the pattern more or less dense by multiplying it for a given number\n",
        "\n",
        "create_barplot(hlf_list, df1_hier[0], df1_hier[1], len(df1), inlg_colors_list, patterns[5]*3, 0)\n",
        "create_barplot(hlf_list, df2_hier[0], df2_hier[1], len(df2), acl_colors_list, None, 1)\n",
        "\n",
        "# Setting various params\n",
        "axes.set_xlabel(\"Metric family groups\")\n",
        "axes.set_ylabel('Percentage')\n",
        "axes.set_title('Metric family use per venue')\n",
        "plt.xticks(range(len(hlf_list)), hlf_list, rotation='vertical')\n",
        "\n",
        "# axes.legend(loc=\"upper right\")\n",
        "\n",
        "#axes.legend(['INLG 2023', 'ACL 2023'])\n",
        "\n",
        "# # shifting labels, needs manual setting by trials\n",
        "# # for metric family = 0.18, 0.4\n",
        "# shift_1 = 0.18\n",
        "# shift_2 = 0.4\n",
        "\n",
        "# # Get the current tick positions and labels\n",
        "# current_positions = plt.xticks()[0]\n",
        "# current_positions = [pos - shift_1 for pos in current_positions]\n",
        "# current_labels = acl_labels\n",
        "\n",
        "# # Calculate new tick positions for the additional set of labels\n",
        "# additional_positions = [pos + shift_2 for pos in current_positions]\n",
        "\n",
        "# # Combine original and additional labels and positions\n",
        "# combined_labels = list(current_labels) + inlg_labels\n",
        "# combined_positions = list(current_positions) + additional_positions\n",
        "\n",
        "# Set the combined tick positions and labels\n",
        "# plt.xticks(combined_positions, combined_labels, size = 10)\n",
        "\n",
        "# X axis limits, again needs to be manually adjusted for each measure\n",
        "# if limit>0:\n",
        "# #  raise Warning('Hello')\n",
        "# plt.xlim(-0.45,9.5)\n",
        "\n",
        "#raise Warning('Hello')\n",
        "# #plt.legend(loc='upper right', labels=['INLG 2023', 'ACL 2023']) #old legend\n",
        "# # Custom legend cause I do what I want\n",
        "# legend_elements = [Patch(facecolor='orange', label='Family 1'),\n",
        "#                    Patch(facecolor='orange', label='Family 2'),\n",
        "#                    Patch(facecolor='orange', label='Family 3'),\n",
        "#                    Patch(facecolor='orange', label='Family 4'),\n",
        "#                    Patch(facecolor='orange', label='Need more? Need other colors?')]\n",
        "\n",
        "# # Create the figure\n",
        "# axes.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mQjW9JhSbXQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hlf_list"
      ],
      "metadata": {
        "id": "ER90MNbBSRCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top-k + others split by hlf\n",
        "limit = 10\n",
        "# For metric-level coloring\n",
        "mf_colors = [\"#bf0040\", \"#00b9f3\", \"#008080\", \"#ff8000\", \"#ff0000\", \"#bf8040\", \"#00ff1f\", \"#808bb3\", \"#fb3199\", \"#000000\"]\n",
        "\n",
        "topk_items = [k for k, _ in sorted(summed.items(), key=lambda i: i[1], reverse=True)[:limit]]\n",
        "\n",
        "def get_topk_data(df_dict, colorscheme):\n",
        "\n",
        "  vals = [[df_dict.get(k, 0) for k in topk_items]]\n",
        "  labels = [[k[0] for k in topk_items]]\n",
        "  colors = [[colorscheme[hlf_list.index(k[1])] for k in topk_items]]\n",
        "\n",
        "  hlf_counts = {}\n",
        "  for k, v in df_dict.items():\n",
        "    if k in topk_items:\n",
        "      continue\n",
        "    hlf_counts[k[1]] = hlf_counts.get(k[1], 0) + v\n",
        "\n",
        "  for k, v in sorted(hlf_counts.items(), key=lambda i: i[1], reverse=True):\n",
        "    vals[-1].append(v)\n",
        "    labels[-1].append(\"Other \" + k)\n",
        "    colors[-1].append(colorscheme[hlf_list.index(k)])\n",
        "    vals.append([0] * len(topk_items))\n",
        "    labels.append([''] * len(topk_items))\n",
        "    colors.append([\"#000000\"] * len(topk_items))\n",
        "\n",
        "  vals.pop()\n",
        "  labels.pop()\n",
        "  colors.pop()\n",
        "\n",
        "  return vals, labels, colors\n",
        "\n",
        "df1_topk = get_topk_data(df1_dict, mf_colors)\n",
        "df2_topk = get_topk_data(df2_dict, mf_colors)\n"
      ],
      "metadata": {
        "id": "gTqy0mJSYKsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "#to make the pattern more subtle\n",
        "plt.rcParams['hatch.linewidth'] = 0.5 # 0.1  # originally 1.0\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6, 7))\n",
        "\n",
        "def create_barplot(hlf_list, data, labels, colors, dflen, hatch, pos):\n",
        "\n",
        "  bottoms = np.zeros(len(hlf_list))\n",
        "  for ds, ls, cs in zip(data, labels, colors):\n",
        "    ds = np.array(ds) / dflen * 100  # percentage\n",
        "    axes.bar(np.arange(len(hlf_list)) - 0.15 + 0.3 * pos,\n",
        "             ds,\n",
        "             color=cs,\n",
        "             # position=pos,\n",
        "             width=0.3,\n",
        "             hatch=hatch,\n",
        "             label=ls,\n",
        "             bottom=bottoms,\n",
        "             alpha=0.8)\n",
        "    bottoms += ds\n",
        "\n",
        "  for x, y, s in zip(np.arange(len(hlf_list)) - 0.2 + 0.4 * pos,\n",
        "                     bottoms + 0.1, bottoms):\n",
        "    axes.text(x, y, f'{s:.1f}', fontsize='x-small', horizontalalignment='center')\n",
        "\n",
        "# Plot bar plot for df1\n",
        "# IMPORTANT 1: Remember to update the color/s variable\n",
        "# IMPORTANT 2: You can make the pattern more or less dense by multiplying it for a given number\n",
        "\n",
        "bars_list = [i[0] for i in topk_items] + ['Other']\n",
        "create_barplot(bars_list, df1_topk[0], df1_topk[1], df1_topk[2], len(df1), None, 0)\n",
        "create_barplot(bars_list, df2_topk[0], df2_topk[1], df2_topk[2], len(df2), '////', 1)\n",
        "\n",
        "# Setting various params\n",
        "axes.set_xlabel(\"Metric families\")\n",
        "axes.set_ylabel('% Papers Using')\n",
        "axes.set_title('Metric family use per venue')\n",
        "plt.xticks(range(len(bars_list)), bars_list, rotation='vertical')\n",
        "\n",
        "# axes.legend(loc=\"upper right\")\n",
        "\n",
        "#axes.legend(['INLG 2023', 'ACL 2023'])\n",
        "\n",
        "# # shifting labels, needs manual setting by trials\n",
        "# # for metric family = 0.18, 0.4\n",
        "# shift_1 = 0.18\n",
        "# shift_2 = 0.4\n",
        "\n",
        "# # Get the current tick positions and labels\n",
        "# current_positions = plt.xticks()[0]\n",
        "# current_positions = [pos - shift_1 for pos in current_positions]\n",
        "# current_labels = acl_labels\n",
        "\n",
        "# # Calculate new tick positions for the additional set of labels\n",
        "# additional_positions = [pos + shift_2 for pos in current_positions]\n",
        "\n",
        "# # Combine original and additional labels and positions\n",
        "# combined_labels = list(current_labels) + inlg_labels\n",
        "# combined_positions = list(current_positions) + additional_positions\n",
        "\n",
        "# Set the combined tick positions and labels\n",
        "# plt.xticks(combined_positions, combined_labels, size = 10)\n",
        "\n",
        "# X axis limits, again needs to be manually adjusted for each measure\n",
        "# if limit>0:\n",
        "# #  raise Warning('Hello')\n",
        "# plt.xlim(-0.45,9.5)\n",
        "\n",
        "#raise Warning('Hello')\n",
        "legend = [Patch(facecolor='#808080', hatch=None, label='INLG 2023'),\n",
        "          Patch(facecolor='#808080', hatch='////', label='ACL 2023')]\n",
        "legend += [Patch(facecolor=c, label=hlf) for hlf, c in zip(hlf_list, mf_colors)]\n",
        "plt.legend(handles=legend, loc='upper left', ncol=2) #old legend\n",
        "# # Custom legend cause I do what I want\n",
        "# legend_elements = [Patch(facecolor='orange', label='Family 1'),\n",
        "#                    Patch(facecolor='orange', label='Family 2'),\n",
        "#                    Patch(facecolor='orange', label='Family 3'),\n",
        "#                    Patch(facecolor='orange', label='Family 4'),\n",
        "#                    Patch(facecolor='orange', label='Need more? Need other colors?')]\n",
        "\n",
        "# # Create the figure\n",
        "# axes.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "RsyAptryEWSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlations"
      ],
      "metadata": {
        "id": "v-nGXMnrB4zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inlg_corr = auto_df[auto_df[CONF] == \"INLG 2023\"].drop_duplicates(subset=[ID, CORRELATED])\n",
        "inlg_corr_counts = inlg_corr[CORRELATED].value_counts()\n",
        "\n",
        "\n",
        "acl_corr = auto_df[auto_df[CONF] == \"ACL 2023\"].drop_duplicates(subset=[ID, CORRELATED])\n",
        "acl_corr_counts = acl_corr[CORRELATED].value_counts()\n",
        "\n",
        "comparison = pd.DataFrame({'INLG 2023': inlg_corr_counts, 'ACL 2023': acl_corr_counts}).fillna(0).T\n",
        "comparison_normalized = comparison.div(comparison.sum(axis=1), axis=0) * 100\n",
        "palette = sns.color_palette([\"#c7522a\",\"#e5c185\",\"#fbf2c4\",\"#b8cdab\",\"#74a892\",\"#008585\",\"#4c9eb3\",\"#779af5\",\"#a59cff\",\"#dbcdf0\"], n_colors=4)\n",
        "ax = comparison_normalized.plot(kind='bar', stacked=True, color=palette)\n",
        "\n",
        "labels = [\n",
        "    'No Correlation',\n",
        "    'No Human Evaluation',\n",
        "    'Qualitative Correlation',\n",
        "    'Quantitative Correlation',\n",
        "          ]\n",
        "\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "# Shrink current axis's height by 10% on the bottom\n",
        "box = ax.get_position()\n",
        "ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
        "                 box.width, box.height * 0.9])\n",
        "\n",
        "#plt.title('Relative Makeup of Correlation with Human Evaluation', loc='center')\n",
        "plt.legend(title='Correlated with Human Evaluation?', bbox_to_anchor=(0.5, -0.1), loc='upper center',\n",
        "           labels=labels,\n",
        "           ncols=2)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate percentages on the bars\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy()\n",
        "    if height > 5:\n",
        "      ax.text(x + width / 2, y + height / 2, f'{height:.1f}%', ha='center', va='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r3HItFlCiFXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_df[CONF].unique()"
      ],
      "metadata": {
        "id": "17OOwO91h-aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_df[auto_df[CORRELATED] == \"Correlation with previous human eval\"]"
      ],
      "metadata": {
        "id": "PAbETjoiBLwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_metrics = auto_df[auto_df[CONF] == \"ACL 2023\"][METRIC_NAME].value_counts().nlargest(20)\n",
        "\n",
        "top_metrics.plot(kind='barh')"
      ],
      "metadata": {
        "id": "jU0Q5R0Clo4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_metrics = auto_df[auto_df[CONF] == \"INLG 2023\"][METRIC_NAME].value_counts().nlargest(20)\n",
        "\n",
        "top_metrics.plot(kind='barh')"
      ],
      "metadata": {
        "id": "Xiu-r_bcnJ_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = df_all[df_all[APPENDIX] == 'Yes']\n",
        "all_inlg = len(df_all[df_all[CONF] == \"INLG 2023\"])\n",
        "all_acl = len(df_all[df_all[CONF] == \"ACL 2023\"])\n",
        "app_inlg = len(app[app[CONF] == \"INLG 2023\"])\n",
        "app_acl = len(app[app[CONF] == \"ACL 2023\"])\n",
        "print(f'{app_inlg} metrics ({app_inlg / all_inlg * 100:.2f} %) were reported in the Appendix at INLG 2023.')\n",
        "print(f'{app_acl} metrics ({app_acl / all_acl * 100:.2f} %) were reported in the Appendix at ACL 2023')"
      ],
      "metadata": {
        "id": "oG0drh5vrgq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app"
      ],
      "metadata": {
        "id": "RE3tEcqp5wMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#auto_df[auto_df[ADHOC].str.len() > 0]"
      ],
      "metadata": {
        "id": "O6PPxbMU5xAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all metric family counts to CSV files:\n",
        "\n",
        "all_fam_counts = df_all.groupby([FAMILY])[FAMILY].count()\n",
        "all_fam_counts.to_csv(\"./metric_family_counts.csv\")\n",
        "inlg_fam_counts = (df_all[df_all[CONF] == \"INLG 2023\"]).groupby([FAMILY])[FAMILY].count()\n",
        "inlg_fam_counts.to_csv(\"./inlg_family_counts.csv\")\n",
        "acl_fam_counts = (df_all[df_all[CONF] == \"ACL 2023\"]).groupby([FAMILY])[FAMILY].count()\n",
        "acl_fam_counts.to_csv(\"./acl_family_counts.csv\")"
      ],
      "metadata": {
        "id": "BSM3Z2luxQzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MF2 = \"MF2\"\n",
        "inlg_fam = auto_df[auto_df[CONF] == \"INLG 2023\"].drop_duplicates(subset=[ID, MF2])\n",
        "inlg_fam_counts = inlg_fam[MF2].value_counts()\n",
        "\n",
        "\n",
        "acl_fam = auto_df[auto_df[CONF] == \"ACL 2023\"].drop_duplicates(subset=[ID, MF2])\n",
        "acl_fam_counts = acl_fam[MF2].value_counts()\n",
        "\n",
        "all_fam = auto_df.drop_duplicates(subset=[ID, MF2])\n",
        "all_fam_counts = all_fam[MF2].value_counts()\n",
        "\n",
        "comparison = pd.DataFrame({'INLG 2023': inlg_fam_counts, 'ACL 2023': acl_fam_counts}).fillna(0).T\n",
        "comparison_normalized = comparison.div(comparison.sum(axis=1), axis=0) * 100\n",
        "ax = comparison_normalized.plot(kind='bar', stacked=True)\n",
        "\n",
        "labels = []\n",
        "\n",
        "plt.xlabel('Percentage')\n",
        "\n",
        "\n",
        "#plt.title('Relative Makeup of Correlation with Human Evaluation', loc='center')\n",
        "plt.legend(title='Type of Metric Used', bbox_to_anchor=(1.05, 0.5), loc='center left', ncols=1)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate percentages on the bars\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy()\n",
        "    if height > 5:\n",
        "      ax.text(x + width / 2, y + height / 2, f'{height:.1f}%', ha='center', va='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k-tMpwfEEAcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acl_fam_counts.plot(kind='barh', figsize = (8,6))"
      ],
      "metadata": {
        "id": "2x5sv8_HFirh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inlg_fam_counts.plot(kind='barh', figsize = (8,6))"
      ],
      "metadata": {
        "id": "y_1yRhKoIKug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We noted down that there were two papers (P110 - 8 metrics, P312 - 5 metrics) that used multiple implementations\n",
        "# That is not enough for a graph, so we will merge them to \"Implementation details provided\"\n",
        "\n",
        "auto_df[IMPL] = auto_df[IMPL].replace(\"Multiple implementations used\", \"Implementation details provided\")\n",
        "\n",
        "inlg_impl = auto_df[auto_df[CONF] == \"INLG 2023\"] #.drop_duplicates(subset=[ID, FAMILY])\n",
        "inlg_impl_counts = inlg_impl[IMPL].value_counts()\n",
        "\n",
        "\n",
        "acl_impl = auto_df[auto_df[CONF] == \"ACL 2023\"] #.drop_duplicates(subset=[ID, FAMILY])\n",
        "acl_impl_counts = acl_impl[IMPL].value_counts()\n",
        "\n",
        "\n",
        "\n",
        "comparison = pd.DataFrame({'INLG 2023': inlg_impl_counts, 'ACL 2023': acl_impl_counts}).fillna(0).T\n",
        "comparison_normalized = comparison.div(comparison.sum(axis=1), axis=0) * 100\n",
        "ax = comparison_normalized.plot(kind='bar', stacked=True)\n",
        "\n",
        "labels = [\"No\", \"Yes\"]\n",
        "\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "\n",
        "#plt.title('Relative Makeup of Correlation with Human Evaluation', loc='center')\n",
        "plt.legend(title='Did the authors provide implementation details in the paper?', bbox_to_anchor=(0.5, -0.1), loc='upper center', ncols=2, labels=labels)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate percentages on the bars\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy()\n",
        "    if height > 5:\n",
        "      ax.text(x + width / 2, y + height / 2, f'{height:.1f}%', ha='center', va='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xal_8LOqLRrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_impl = auto_df #.drop_duplicates(subset=[ID, FAMILY])\n",
        "bleu_impl = auto_df[auto_df[FAMILY] == \"BLEU\"].drop_duplicates(subset=[ID, FAMILY, IMPL])\n",
        "rouge_impl = auto_df[auto_df[FAMILY] == \"ROUGE\"].drop_duplicates(subset=[ID, FAMILY, IMPL])\n",
        "all_impl_counts = all_impl[IMPL].value_counts()\n",
        "bleu_impl_counts = bleu_impl[IMPL].value_counts()\n",
        "rouge_impl_counts = rouge_impl[IMPL].value_counts()\n",
        "\n",
        "comparison = pd.DataFrame({'BLEU': bleu_impl_counts, 'ROUGE': rouge_impl_counts}).fillna(0).T\n",
        "comparison_normalized = comparison.div(comparison.sum(axis=1), axis=0) * 100\n",
        "ax = comparison_normalized.plot(kind='bar', stacked=True)\n",
        "\n",
        "labels = []\n",
        "\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "\n",
        "#plt.title('Relative Makeup of Correlation with Human Evaluation', loc='center')\n",
        "plt.legend(title='Type of Metric Used', bbox_to_anchor=(0.5, -0.1), loc='upper center', ncols=2)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate percentages on the bars\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy()\n",
        "    if height > 5:\n",
        "      ax.text(x + width / 2, y + height / 2, f'{height:.1f}%', ha='center', va='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3n746wAjuvjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What variants of BLEU are used?\n",
        "bleu_types = auto_df[auto_df[FAMILY] == \"BLEU\"].groupby(['Display Name'])['Display Name'].count()\n",
        "bleu_types = bleu_types.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "buhJWVIeCA3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What variants of ROUGE are used?\n",
        "rouge_types = auto_df[auto_df[FAMILY] == \"ROUGE\"].groupby(['Display Name'])['Display Name'].count()\n",
        "rouge_types = rouge_types.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "-x1m8CahAsRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
        "fig.set_figwidth(10)\n",
        "fig.tight_layout()\n",
        "bleu_types.plot(kind=\"bar\", xlabel=\"\", ylabel=\"Count\", color=\"#779af5\", ax=axes[0])\n",
        "rouge_types.plot(kind=\"bar\", xlabel=\"\", color=\"#c7522a\", ax=axes[1])"
      ],
      "metadata": {
        "id": "fYePTszIJJ8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "impl_ids = {}\n",
        "for impl in auto_df[IMPL].unique():\n",
        "  impl_ids[impl] = list(auto_df[auto_df[IMPL] == impl][ID].unique())\n",
        "import json\n",
        "with open('impl_ids.json', 'w') as f:\n",
        "  json.dump(impl_ids, f)"
      ],
      "metadata": {
        "id": "oUdy73oAFr4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rationales = auto_df['Notes: Rational']"
      ],
      "metadata": {
        "id": "zC_R3oAF1jBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "follower_count = 0\n",
        "correlate = 0\n",
        "empty = 0\n",
        "other = []\n",
        "vals = []\n",
        "v_bin = []\n",
        "import re\n",
        "for r in rationales:\n",
        "  rl =  r.strip().lower()\n",
        "  if r == \"\" or re.match(\"(none given\\.?|not given)\", rl):\n",
        "    empty += 1\n",
        "    vals.append('None')\n",
        "    v_bin.append(0)\n",
        "  elif 'correlat' in rl:\n",
        "    correlate += 1\n",
        "    vals.append('Correlation')\n",
        "    v_bin.append(1)\n",
        "  elif re.search('(recent|previous|earlier|following|widely|staple|commonly|conventional |20\\d\\d)', rl):\n",
        "    follower_count += 1\n",
        "    vals.append('Following')\n",
        "    v_bin.append(1)\n",
        "  else:\n",
        "    other.append(r)\n",
        "    vals.append('Quality')\n",
        "    v_bin.append(1)\n",
        "print(f'{follower_count} ({follower_count/len(rationales)*100:.1f} %) metrics were used because the authors followed previous work.')\n",
        "print(f'{correlate} ({correlate/len(rationales)*100:.1f} %) metrics were used because they correlate with human judgment.')\n",
        "print(f'{empty} ({empty/len(rationales)*100:.1f} %) metrics had no rationale for being used.')\n",
        "print(f'{len(other)} ({len(other)/len(rationales)*100:.1f} %) metrics provided a rationale (other than following previous work or previously shown correlation with human judgment).')"
      ],
      "metadata": {
        "id": "ZPrCaCDJ6zwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_df['RATB'] = v_bin\n",
        "auto_df['RAT'] = vals"
      ],
      "metadata": {
        "id": "v0Kh4_AHQFzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_m = auto_df.groupby(by=ID)[METRIC_NAME].agg(lambda x: len(list(x))).to_frame()\n",
        "grouped_r = auto_df.groupby(by=ID)['RAT'].agg(lambda x: list(x)).to_frame()\n",
        "grouped_rb = auto_df.groupby(by=ID)['RATB'].agg(lambda x: 1 if sum(x) >=1 else 0).to_frame()\n",
        "\n",
        "grouped = grouped_m.join(grouped_r)\n",
        "groupedrb = grouped_m.join(grouped_r)"
      ],
      "metadata": {
        "id": "8-vnhE7wQQvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a binary matrix for RAT values\n",
        "all_rat_values = ['None', 'Correlation', 'Following', 'Quality']\n",
        "for rat in all_rat_values:\n",
        "    grouped[rat] = grouped['RAT'].apply(lambda x: x.count(rat) / len(x))\n",
        "\n",
        "# Aggregate counts of metrics and RAT values\n",
        "df_agg = grouped.groupby('Metric name')[all_rat_values].sum().reset_index()\n",
        "\n",
        "# Plot the heatmap\n",
        "df_melted = df_agg.melt(id_vars=['Metric name'], value_vars=all_rat_values,\n",
        "                        var_name='Rationale', value_name='Count')\n",
        "\n",
        "heatmap_data = df_melted.pivot(index=\"Metric name\", columns=\"Rationale\", values=\"Count\")\n",
        "plt.figure(figsize=(7, 7))\n",
        "palette = [\"#fbf2c4\",\"#b8cdab\",\"#74a892\",\"#008585\", \"#4c9eb3\"]\n",
        "cmap = mcolors.LinearSegmentedColormap.from_list(\"n\", palette)\n",
        "ax = sns.heatmap(heatmap_data, annot=True, cmap=cmap)\n",
        "ax.set(xlabel=\"What rationale was given for using a metric?\", ylabel=\"How many metrics were used within one paper?\")\n",
        "#plt.title('Heatmap of Metric Counts vs Rationales given')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iy7oTwsARpdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped[grouped[METRIC_NAME] > 8].sort_values(by=METRIC_NAME)"
      ],
      "metadata": {
        "id": "iDOpUfYjW-p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inlg = auto_df[auto_df[CONF] == \"INLG 2023\"] #.drop_duplicates(subset=[ID, FAMILY])\n",
        "inlg_train_counts = inlg[TRAIN].value_counts()\n",
        "\n",
        "\n",
        "acl = auto_df[auto_df[CONF] == \"ACL 2023\"] #.drop_duplicates(subset=[ID, FAMILY])\n",
        "acl_train_counts = acl[TRAIN].value_counts()\n",
        "\n",
        "\n",
        "\n",
        "comparison = pd.DataFrame({'INLG 2023': inlg_train_counts, 'ACL 2023': acl_train_counts}).fillna(0).T\n",
        "comparison_normalized = comparison.div(comparison.sum(axis=1), axis=0) * 100\n",
        "ax = comparison_normalized.plot(kind='bar', stacked=True)\n",
        "\n",
        "labels = []\n",
        "\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "\n",
        "#plt.title('Relative Makeup of Correlation with Human Evaluation', loc='center')\n",
        "plt.legend(title='Is the metric trainable?', bbox_to_anchor=(0.5, -0.1), loc='upper center', ncols=2)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate percentages on the bars\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy()\n",
        "    if height > 5:\n",
        "      ax.text(x + width / 2, y + height / 2, f'{height:.1f}%', ha='center', va='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RRnx8Dne7NyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_df[SRC_REF] = auto_df[SRC] + auto_df[REF]\n",
        "replacements = {\n",
        "    \"FALSETRUE\": \"Reference-based metric\",\n",
        "    \"TRUEFALSE\": \"Source-based metric\",\n",
        "    \"TRUETRUE\": \"Metric uses both source and reference\",\n",
        "    \"FALSEFALSE\": \"Metric uses output only\"\n",
        "}\n",
        "auto_df[SRC_REF] = auto_df[SRC_REF].map(replacements)\n",
        "auto_df[SRC_REF].unique()"
      ],
      "metadata": {
        "id": "2UD1idrnEYxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inlg = auto_df[auto_df[CONF] == \"INLG 2023\"] #.drop_duplicates(subset=[ID, FAMILY])\n",
        "inlg_srcref_counts = inlg[SRC_REF].value_counts()\n",
        "\n",
        "\n",
        "acl = auto_df[auto_df[CONF] == \"ACL 2023\"] #.drop_duplicates(subset=[ID, FAMILY])\n",
        "acl_srcref_counts = acl[SRC_REF].value_counts()\n",
        "\n",
        "palette = sns.color_palette([\"#c7522a\",\"#e5c185\",\"#fbf2c4\",\"#b8cdab\",\"#74a892\",\"#008585\",\"#4c9eb3\",\"#779af5\",\"#a59cff\",\"#dbcdf0\"], n_colors=4)\n",
        "\n",
        "comparison = pd.DataFrame({'INLG 2023': inlg_srcref_counts, 'ACL 2023': acl_srcref_counts}).fillna(0).T\n",
        "comparison_normalized = comparison.div(comparison.sum(axis=1), axis=0) * 100\n",
        "ax = comparison_normalized.plot(kind='bar', stacked=True, color=palette, ylim=(0,100))\n",
        "\n",
        "labels = []\n",
        "\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "\n",
        "#plt.title('Relative Makeup of Correlation with Human Evaluation', loc='center')\n",
        "plt.legend(title='Type of Metric Used', bbox_to_anchor=(0.5, -0.08), loc='upper center', ncols=2)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate percentages on the bars\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy()\n",
        "    if height > 5:\n",
        "      ax.text(x + width / 2, y + height / 2, f'{height:.1f}%', ha='center', va='center')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8AIhHo8nEWwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: if we want to use this, we will definitely need to squish some into \"Other\"\n",
        "auto_tasks = auto_df.copy(deep=True)\n",
        "auto_tasks[TASK] = auto_tasks[TASK].apply(lambda x: list(x))\n",
        "auto_tasks = auto_tasks.explode(TASK).drop_duplicates(subset=[ID, TASK])\n",
        "auto_tasks = auto_tasks[~auto_tasks[TASK].isin(['multiple (list all)', 'other (please specify)'])]\n",
        "\n",
        "inlg_task = auto_tasks[auto_tasks[CONF] == \"INLG 2023\"]\n",
        "inlg_task_counts = inlg_task[TASK].value_counts()\n",
        "\n",
        "\n",
        "acl_task = auto_tasks[auto_tasks[CONF] == \"ACL 2023\"]\n",
        "acl_task_counts = acl_task[TASK].value_counts('')\n",
        "\n",
        "\n",
        "\n",
        "comparison = pd.DataFrame({'INLG 2023': inlg_task_counts, 'ACL 2023': acl_task_counts}).fillna(0).T\n",
        "#comparison_normalized = comparison.div(comparison.sum(axis=1), axis=0) * 100\n",
        "ax = comparison.plot(kind='bar', stacked=True, figsize=(6, 10))\n",
        "\n",
        "labels = []\n",
        "\n",
        "plt.ylabel('Percentage')\n",
        "\n",
        "\n",
        "#plt.title('Relative Makeup of Correlation with Human Evaluation', loc='center')\n",
        "plt.legend(title='Task Representation at both venues', bbox_to_anchor=(0.5, -0.1), loc='upper center', ncols=2)\n",
        "plt.xticks(rotation='horizontal')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate percentages on the bars\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy()\n",
        "    if height > 5:\n",
        "      ax.text(x + width / 2, y + height / 2, f'{height:.1f}%', ha='center', va='center')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yszsJoUUIsLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inlg_task_counts"
      ],
      "metadata": {
        "id": "-U_0_Pff96hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_tasks = auto_df.copy(deep=True)\n",
        "auto_tasks[TASK] = auto_tasks[TASK].apply(lambda x: list(x))\n",
        "auto_tasks = auto_tasks.explode(TASK)\n",
        "auto_tasks = auto_tasks[~auto_tasks[TASK].isin(['multiple (list all)', 'other (please specify)'])]\n",
        "\n",
        "task_plot_map = {\n",
        "    'question answering': 'question\\nanswering',\n",
        "    'machine translation': 'machine\\ntranslation',\n",
        "    'question generation': 'question\\ngeneration',\n",
        "    'paraphrasing / lossless simplification': 'paraphrasing',\n",
        "    'feature-controlled generation': 'feature-controlled\\ngeneration',\n",
        "    'end-to-end text generation': 'end-to-end text\\ngeneration',\n",
        "    'dialogue turn generation': 'dialogue turn\\ngeneration',\n",
        "    'summarisation (text-to-text)': 'summarisation',\n",
        "    'data-to-text generation': 'data-to-text\\ngeneration',\n",
        "    'story generation': 'story\\ngeneration'\n",
        "}\n",
        "plotting_data = dict()\n",
        "task_counts = auto_tasks.drop_duplicates(subset=[ID, TASK])[TASK].value_counts()\n",
        "\n",
        "\n",
        "for t in reversed(task_counts.index):\n",
        "  if task_counts[t] < 6:\n",
        "    continue\n",
        "  largest = auto_tasks[auto_tasks[TASK] == t][MF2].value_counts().head(4).index.tolist()\n",
        "  large = auto_tasks.assign(MF2 = np.where(auto_tasks[MF2].isin(largest), auto_tasks[MF2], 'Other'))\n",
        "  plotting_data[task_plot_map[t]] = large[large[TASK] == t][MF2].value_counts()\n",
        "\n",
        "comparison = pd.DataFrame(plotting_data).fillna(0).T\n",
        "comparison_normalized = comparison.div(comparison.sum(axis=1), axis=0) * 100\n",
        "\n",
        "# Sort the values within each task and move 'Other' to the last position\n",
        "def sort_and_move_other(df):\n",
        "    sorted_rows = []\n",
        "    for idx, row in df.iterrows():\n",
        "        sorted_row = row.sort_values(ascending=False)\n",
        "        if 'Other' in sorted_row.index:\n",
        "            other_value = sorted_row.pop('Other')\n",
        "            sorted_row['Other'] = other_value\n",
        "        sorted_rows.append(sorted_row)\n",
        "    return pd.DataFrame(sorted_rows, index=df.index)\n",
        "\n",
        "comparison_normalized = sort_and_move_other(comparison_normalized)\n",
        "\n",
        "# Prepare the data for plotting\n",
        "comparison_normalized = comparison_normalized.reset_index().rename(columns={'index': 'Task'})\n",
        "\n",
        "# Set up the color palette\n",
        "#palette = sns.color_palette(\"Accent\", n_colors=comparison_normalized.shape[1] - 1)\n",
        "palette = sns.color_palette([\"#c7522a\",\"#e5c185\",\"#fbf2c4\",\"#b8cdab\",\"#74a892\",\"#008585\",\"#4c9eb3\",\"#779af5\",\"#a59cff\",\"#dbcdf0\"], n_colors=comparison_normalized.shape[1] - 1)\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(9, 7))\n",
        "\n",
        "# Function to plot sorted stacked bars\n",
        "def plot_sorted_bars(ax, df, palette):\n",
        "    bottoms = np.zeros(len(df))\n",
        "    for i, column in enumerate(df.columns[1:]):\n",
        "        color = palette[i] if column != 'Other' else 'lightgray'\n",
        "        ax.barh(\n",
        "            df['Task'], df[column],\n",
        "            left=bottoms, label=column, color=color\n",
        "        )\n",
        "        bottoms += df[column]\n",
        "\n",
        "plot_sorted_bars(ax, comparison_normalized, palette)\n",
        "\n",
        "# Add annotations to the bars\n",
        "for i, row in comparison_normalized.iterrows():\n",
        "    cumulative_percentage = 0\n",
        "    for j, (column, value) in enumerate(row.items()):\n",
        "        if column == 'Task':\n",
        "            continue\n",
        "        if value > 5:\n",
        "            ax.text(\n",
        "                cumulative_percentage + value / 2,\n",
        "                i,\n",
        "                f'{value:.1f}%',\n",
        "                ha='center', va='center',\n",
        "                fontsize=10, color='black'\n",
        "            )\n",
        "        cumulative_percentage += value\n",
        "\n",
        "ax.set_xlabel('Percentage')\n",
        "#ax.set_ylabel('Task')\n",
        "#ax.set_title('Relative Makeup of Metric Use per Task')\n",
        "ax.legend(title='Metric', bbox_to_anchor=(0.4, -0.12), loc='upper center', borderaxespad=0., ncols=5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AMLYMddiKjip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To analyze the number of metrics used per paper\n",
        "acl = auto_df[auto_df[CONF] == \"ACL 2023\"]\n",
        "inlg = auto_df[auto_df[CONF] == \"INLG 2023\"]\n",
        "\n",
        "ag = acl.groupby(by=ID)[METRIC_NAME].apply(lambda x: len(list(x)))\n",
        "ig = inlg.groupby(by=ID)[METRIC_NAME].apply(lambda x: len(list(x)))\n",
        "\n",
        "ig_vals = ig.value_counts().sort_index()"
      ],
      "metadata": {
        "id": "i34GKlrBja8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ag_vals = ag.value_counts().sort_index()"
      ],
      "metadata": {
        "id": "_4fWejk98Epq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = auto_df.groupby(by=ID)[FAMILY].agg((lambda x: set(x)))\n",
        "\n",
        "df_agg = grouped.reset_index()\n",
        "\n",
        "# Transform sets to binary matrix\n",
        "all_items = sorted(set().union(*df_agg[FAMILY]))\n",
        "binary_matrix = df_agg[FAMILY].apply(lambda x: [1 if item in x else 0 for item in all_items])\n",
        "binary_df = pd.DataFrame(binary_matrix.tolist(), columns=all_items)\n",
        "\n",
        "# Calculate co-occurrence matrix\n",
        "co_occurrence_matrix = np.dot(binary_df.T, binary_df)\n",
        "#np.fill_diagonal(co_occurrence_matrix, 0)\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "palette = [\"#fbf2c4\",\"#b8cdab\",\"#74a892\",\"#008585\", \"#4c9eb3\"]\n",
        "cmap = mcolors.LinearSegmentedColormap.from_list(\"n\", palette)\n",
        "sns.heatmap(co_occurrence_matrix, annot=True, cmap=cmap, xticklabels=all_items, yticklabels=all_items)\n",
        "plt.title('Co-occurrence Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dOigD50s9QBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = auto_df.groupby(by=ID)[MF2].agg((lambda x: set(x)))\n",
        "\n",
        "df_agg = grouped.reset_index()\n",
        "\n",
        "# Transform sets to binary matrix\n",
        "all_items = sorted(set().union(*df_agg[MF2]))\n",
        "binary_matrix = df_agg[MF2].apply(lambda x: [1 if item in x else 0 for item in all_items])\n",
        "binary_df = pd.DataFrame(binary_matrix.tolist(), columns=all_items)\n",
        "\n",
        "# Calculate co-occurrence matrix\n",
        "co_occurrence_matrix = np.dot(binary_df.T, binary_df)\n",
        "#np.fill_diagonal(co_occurrence_matrix, 0)\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "palette = [\"#fbf2c4\",\"#b8cdab\",\"#74a892\",\"#008585\", \"#4c9eb3\"]\n",
        "cmap = mcolors.LinearSegmentedColormap.from_list(\"n\", palette)\n",
        "sns.heatmap(co_occurrence_matrix, annot=True, cmap=cmap, xticklabels=all_items, yticklabels=all_items)\n",
        "#plt.title('Co-occurrence Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T3ySH4SKE-nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_heatmap(df, col1, col2, yname=None, xname=None, title=None, labels=None):\n",
        "    \"\"\"\n",
        "    Plots a heatmap showing the relationship between two string columns.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The input dataframe.\n",
        "    col1 (str): The name of the first string column.\n",
        "    col2 (str): The name of the second string column.\n",
        "    \"\"\"\n",
        "\n",
        "    if xname is None:\n",
        "      xname = col1\n",
        "    if yname is None:\n",
        "      yname = col2\n",
        "    if not title:\n",
        "      title = f'Heatmap of {xname} vs {yname}'\n",
        "    # Create a contingency table (cross-tabulation)\n",
        "    contingency_table = pd.crosstab(df[col1], df[col2])\n",
        "\n",
        "    # Plot the heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    palette = [\"#fbf2c4\",\"#b8cdab\",\"#74a892\",\"#008585\", \"#4c9eb3\"]\n",
        "    cmap = mcolors.LinearSegmentedColormap.from_list(\"n\", palette)\n",
        "    ax = sns.heatmap(contingency_table, annot=True, cmap=cmap, fmt='d')\n",
        "    ax.set(xlabel=xname, ylabel=None)\n",
        "    if labels is not None:\n",
        "      ax.set_yticklabels(labels)\n",
        "    plt.xticks()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UaQR7Diy_Jgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=['No Correlation with\\nHuman Evaluation', 'Qualitative Correlation\\nwith Human Evaluation', 'Quantitative Correlation\\nwith Human Evaluation', 'No Human Evaluation']\n",
        "plot_heatmap(auto_df, CORRELATED, 'RAT', 'Correlation with Human Evaluation', 'Rationale', labels=labels)"
      ],
      "metadata": {
        "id": "Qv8Wki-KAChX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inlg_auto = auto_df[auto_df[CONF] == \"INLG 2023\"]\n",
        "acl_auto = auto_df[auto_df[CONF] == \"ACL 2023\"]\n",
        "print(len(inlg_auto))\n",
        "print(len(acl_auto))"
      ],
      "metadata": {
        "id": "8fB9JT9wItN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((inlg_auto[IMPL].value_counts()))\n",
        "print((acl_auto[IMPL].value_counts()))"
      ],
      "metadata": {
        "id": "1T0Q5Ph3wZjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "27D8iGJIxOJ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
