{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1uNJV_SRBP0XeMvco6cZjt6eWuk-LslHY","timestamp":1715028311378}],"authorship_tag":"ABX9TyP+jTqpJPZUeQmn2yGP0GcR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import the necessary libraries and authenticate the user to access the Google Sheet:"],"metadata":{"id":"TwgwMiUccT8g"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"X6KKSyKqryKJ","executionInfo":{"status":"ok","timestamp":1715670538092,"user_tz":-120,"elapsed":1588,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}}},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","import gspread\n","from google.auth import default\n","creds, _ = default()\n","\n","\n","\n","gc = gspread.authorize(creds)"]},{"cell_type":"markdown","source":["Define functions and set columns as variable names:"],"metadata":{"id":"amp4RsFyeYKg"}},{"cell_type":"code","source":["# Sheet names to analyze\n","SHEETS = [\"INLG 2023\", \"ACL 2023\"]\n","\n","# List the column names as constants to prevent typos\n","ID = \"ACL Paper ID\"\n","METRIC_NAME = \"Metric name\"\n","NEWLY = \"Newly introduced?\"\n","APPENDIX = \"Appendix\"\n","TASK = \"Updated Task\"\n","#TASK_OLD = \"Task\"\n","#INK_TO_METRIC = \"Link to the Metric Paper\"\n","#PAPER_LINK = \"Link to the Paper\"\n","CORRELATED = \"Corrleated w/ Human Evaluation?\"\n","ANNOTATOR = \"Annotator\"\n","METRIC_IMPL = \"Metric Implementations\"\n","RATIONALE = \"Notes: Rational\"\n","COMMENTS = \"Comments\"\n","CONF = \"Conf\"\n","SURVEY = \"Survey\"\n","\n","#CLOSED_CLASS_COLUMNS = [NEWLY, APPENDIX, CORRELATED]\n","#OPEN_CLASS_COLUMNS = [METRIC_NAME, TASK, LINK_TO_METRIC, PAPER_LINK]\n","# Metric needs to be evaluated separately and then we need to merge it to the paper ID to have a unique key and match corresponding lines\n","COLUMNS_TO_EVALUATE = [NEWLY, APPENDIX, TASK, METRIC_IMPL, CORRELATED, RATIONALE, COMMENTS]"],"metadata":{"id":"IUpR5Yjx6azo","executionInfo":{"status":"ok","timestamp":1715670538093,"user_tz":-120,"elapsed":9,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","# The following snippet checks for the number of annotations per one paper per annotator and reports discrepancies\n","def print_metric_counts(df):\n","  counts = df.groupby([ID, ANNOTATOR]).size().reset_index(name='count')\n","  agreed = disagreed = 0\n","  for i, group in counts.groupby(ID):\n","      unique_counts = group['count'].nunique()\n","      if unique_counts > 1:\n","          disagreed += 1\n","          annotations_info = []\n","          for annotator, count in zip(group[ANNOTATOR], group['count']):\n","              annotations_info.append(f\"{annotator} reported {count} metrics\")\n","          print(f\"For paper id {i}, {'; '.join(annotations_info)}\")\n","      else:\n","        agreed += 1\n","  print(f'With {agreed} agreements and {disagreed} disagreements, annotators agreed in {100 * agreed / float(agreed + disagreed)}% cases.')\n","\n","# Normalize the metric string\n","def normalize_metric(metric):\n","  metric = re.sub('[- +@]+', '', metric) # Remove spaces and other special symbols that might occur - keeping parentheses deliberately\n","  metric = metric.lower() # Lowercase everything\n","  metric = re.sub('(#survey|\\(corpus\\))', '', metric)\n","  if metric in metric_mapping.keys():\n","    return metric_mapping[metric]\n","  return metric\n","\n","# Some metrics were reported as several metrics in one line, split them to keep them consistent\n","def split_grouped_metrics(df):\n","\n","\n","\n","# Normalize URLs\n","def normalize_urls(url):\n","  return re.sub('(/|\\.pdf)$', '', url)\n","\n","def normalize_task(taskstring):\n","  if taskstring is None:\n","    return frozenset()\n","  if isinstance(taskstring, frozenset):\n","    return taskstring\n","  subtasks = re.split('[:;,]', taskstring)\n","  updated = []\n","  for t in subtasks:\n","    task = t.strip().lower()\n","    if task != \"\":\n","      if task in task_mapping.keys():\n","        task = task_mapping[task]\n","      updated.append(task)\n","\n","  return frozenset(updated)"],"metadata":{"id":"dXvAiUGb_IlZ","executionInfo":{"status":"ok","timestamp":1715670538093,"user_tz":-120,"elapsed":8,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["Open the worksheet and make it into a DataFrame + Normalization"],"metadata":{"id":"Q2tQssy2eOlc"}},{"cell_type":"code","source":["dfs = []\n","for sheet in SHEETS:\n","  worksheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1NU6IlxhYg515RLjsVxNW5FS0ChWbIKi3yrrdfqEvsRM/').worksheet(sheet)\n","\n","  # get_all_values gives a list of rows.\n","  rows = worksheet.get_all_values()\n","\n","  # Convert to a DataFrame and render.\n","  df = pd.DataFrame.from_records(rows[1:], columns=rows[0])\n","  # Sometimes there will be blank rows with \"Updated Task\"\n","  df = df[df[ID] != \"\"]\n","  df[CONF] = sheet\n","  df.reset_index(inplace=True, drop=True)\n","  dfs.append(df)\n","df = pd.concat(dfs, ignore_index=True)"],"metadata":{"id":"OpxEFlrjs3Ih","executionInfo":{"status":"ok","timestamp":1715670544316,"user_tz":-120,"elapsed":6231,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["names_to_split = {\n","    \"accuracy/p/r/f1\": [\"accuracy\", \"precision\", \"recall\", \"f1\"],\n","    \"bleu{1,2}\": [\"bleu1\", \"bleu2\"],\n","    \"distinctngrams(dist{1,2,3})\": ['distinctunigrams', 'distinctbigrams', 'distincttrigrams'],\n","    \"dist{1,2,3}\": ['distinctunigrams', 'distinctbigrams', 'distincttrigrams'],\n","    \"repnmetricsforn=2,3,4\": ['bigramrepetition', 'trigramrepetition', '4gramrepetition'],\n","    \"rouge{1,2,l}\": [\"rouge1\", \"rouge2\", \"rougel\"],\n","    \"rouge{1,2}\": [\"rouge1\", \"rouge2\"]\n","}"],"metadata":{"id":"wvjKK0Es-OPH","executionInfo":{"status":"ok","timestamp":1715672143759,"user_tz":-120,"elapsed":514,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["metric_mapping = {\n","    'harmonicmean(hmean)between(1−pbleu)andbleu': 'harmonicmean(pbleubleu)',\n","    'harmonicmeanof1pbleuandbleu': 'harmonicmean(pbleubleu)',\n","    'hmeanbetween(1pbleu)andbleu':'harmonicmean(pbleubleu)',\n","    'harmonicmeanofbleu4andstyleaccuracy': 'harmonicmean(bleu4styleaccuracy)',\n","    'pairwisebleu': 'pbleu',\n","    'pbleu(selfbleu)': 'pbleu',\n","    'em': 'exactmatch',\n","    'exactmatch(em)': 'exactmatch',\n","    'inform(rate)': 'inform',\n","    'success(rate)': 'success',\n","    'combinescore(informandrate)': 'combinedscore(informandrate)',\n","    'bleu(4)': 'bleu4',\n","    'accuracy(?)': 'accuracy',\n","    'macroaveragedf1score(f1)': 'f1',\n","    'sensitivity': 'demetrbenchmarksensitivityscores',\n","    'bleurtbase': 'bleurt',\n","    'allmpnetbasev2': 'mpnetcosinesimilarity',\n","    'negmpnet': 'negmpnetcosinesimilarity',\n","    'distinct1': 'distinctunigrams',\n","    'distinct2': 'distinctbigrams',\n","    'distinct4': 'distinct4grams',\n","    'dist1': 'distinctunigrams',\n","    'dist2': 'distinctbigrams',\n","    'dist3': 'distincttrigrams',\n","    'distinct3': 'distincttrigrams',\n","    'sacrebleu': 'bleu',\n","    'bleuscore': 'bleu',\n","    'rquge': 'rouge',\n","    'bertscorefscore': 'bertscoref1',\n","    'bertscorep': 'bertscoreprecision',\n","    'bertscorer': 'bertscorerecall',\n","    'beatf1': 'bertscoref1',\n","    'bertscorefmeasure': 'bertscoref1',\n","    'bleurtscore': 'bleurt'\n","}"],"metadata":{"id":"lTcwB4QF3nyU","executionInfo":{"status":"ok","timestamp":1715672142776,"user_tz":-120,"elapsed":447,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["task_mapping = {\n","    \"natural language entailment)\": \"natural language inference\",\n","    \"data-text generation\": \"data-to-text generation\",\n","    \"data-to-text\": \"data-to-text generation\",\n","    \"dialogue generation\": \"dialogue turn generation\",\n","    \"dialogue response\": \"dialogue turn generation\",\n","    \"dialouge\": \"dialogue turn generation\",\n","    \"open-ended dialogue\": \"dialogue turn generation\",\n","    \"task-oriented dialouge\": \"dialogue turn generation\",\n","    \"paraphrase generation\": \"paraphrasing / lossless simplification\",\n","    \"paraphrasing/lossless simplification\": \"paraphrasing / lossless simplification\",\n","    \"text simplification\": \"compression / lossy simplification\",\n","    \"question-generation\": \"question generation\",\n","    \"quora question pairs\": \"question answering\",\n","    \"and question answering\": \"question answering\",\n","    \"simile generation\": \"simile generation (text-to-text)\",\n","    \"story-generation\": \"story generation\",\n","    \"text summarization\": \"summarisation (text-to-text)\",\n","    \"summarisation\": \"summarisation (text-to-text)\",\n","    \"summarization\": \"summarisation (text-to-text)\",\n","    \"summarization (text-to-text)\": \"summarisation (text-to-text)\",\n","    \"evaluate semantic diversity between two natural language \\ngeneration\": \"evaluate semantic diversity between two natural language generation\",\n","    \"updated task\": \"\"\n","}"],"metadata":{"id":"jnod6kamyAtD","executionInfo":{"status":"ok","timestamp":1715670544317,"user_tz":-120,"elapsed":14,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Normalize\n","df[SURVEY] = df[METRIC_NAME].str.contains(\"#survey\")\n","df[METRIC_NAME] = df[METRIC_NAME].apply(normalize_metric)\n","df[TASK] = df[TASK].apply(normalize_task)"],"metadata":{"id":"ksciZvly8_px","executionInfo":{"status":"ok","timestamp":1715670544317,"user_tz":-120,"elapsed":12,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["print(sorted(df[METRIC_NAME].unique()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItfzwRL5D6kB","executionInfo":{"status":"ok","timestamp":1715671164719,"user_tz":-120,"elapsed":380,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}},"outputId":"4de456de-06dd-4638-aa41-cbb343f50ba1"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["['', 'accuracy', 'accuracy(sentiment)', 'accuracy(tense)', 'accuracy(topic)', 'accuracy/p/r/f1', 'accuracyofcomparator', 'accuracyofkeywordinclusion', 'accuracyofkeywordinclusionatspecifiedposition', 'accuracyofpredictingpvalue', 'accuracyofvehicle', 'actclassificationaccuracy(aacc)roberta', 'actmultipleattributeevaluation(amae)', 'add', 'agreementthenumberofquestionsgeneratedbygpt2(#q)matchesthenumberofgpt3annotatedquestionsforagivenproblem', 'alignscore', 'anli', 'attrauto', 'auc', 'auroc', 'average', 'averageddistinctiveness', 'averagelength', 'averageofrouge1,rouge2,androugel', 'averagesentencelength', 'backwardbleu', 'bartscore', 'bartscorefaithfulness', 'bartscorefscore', 'bartscoreprecision', 'bartscorerecall', 'beatf1', 'bertscore', 'bertscoref1', 'bertscorefmeasure', 'bertscoreprecision', 'bertscorerecall', 'bias', 'bias(absolutevalueofrelevance50)', 'bigramttr', 'blanc', 'bleu', 'bleu1', 'bleu2', 'bleu3', 'bleu4', 'bleualc(areaunderlearningcurve)', 'bleun', 'bleurt', 'bleurtscore', 'bleu{1,2}', 'cext', 'chexpertfactuality', 'chrf', 'cider', 'coherence', 'cometqe', 'completionsensitivityscore', 'copysuccessrate(word)', 'corpusbleu', 'correctness', 'cosinedistance', 'coverage', 'coverage(ofkeywords)', 'croppedsentenceratio', 'ctc', 'ctrleval', 'customtrainedrelevanceclassifier', 'd(omain)accuracy', 'd(omainslot)v(alue)accuracy', 'dadd', 'ddelete', 'debertaxxlargev2', 'decompeval', 'delete', 'detoxification', 'detoxify', 'dist1', 'dist2', 'dist3', 'distinct3', 'distinct4grams', 'distinctbigrams', 'distinctness', 'distinctngrams', 'distinctngrams(dist{1,2,3})', 'distincttrigrams(proportion)', 'distinctunigrams', 'distn(4?)', 'dist{1,2,3}', 'div4', 'diversity', 'diversity(ofquestions)', 'diversity1', 'diversity2', 'diversity3', 'diversityscore', 'dkeep', 'dlex', 'dsari', 'dsyn', 'editdistance', 'embeddingsimilarity', 'emotionclassificationaccuracy(eacc)roberta', 'emotionmultipleattributeevaluation(emae)', 'ent4', 'exactmatch', 'exactmatchaccuracy', 'extractivefragmentdensity(ρ)', 'f1', 'f1(lexicalsimplification)', 'f1score(appraisal)', 'factcc', 'feqa', 'fkgl', 'fleschkincaidgradelevel(fkgl)', 'fleschkincaidgradelevelreadability(fkgl)', 'fleschreadingeasescore', 'fluency', 'fluency(perplexity)', 'formatf1', 'forwardcrossentropyoflearneddistribution', 'forwardkldivergenceoflearneddistribution', 'geommean(.)', 'geommean(acc,sim,fl)', 'gptppl', 'gptrank', 'grammar(gram)', 'grammaticality', 'gscore', 'harmonicmean(pbleubleu)', 'hauser', 'human', 'human#offactualerrors', 'human#ofhallucinationerrors', 'human#ofinformationmisses', 'human(absentinformation)', 'human(accuracy)', 'human(adequacy)', 'human(appropriateness)', 'human(argumentquality)', 'human(attribute)', 'human(beingwrittenbyanativespeaker)', 'human(beliefstatefaithfulness)', 'human(classifyingerrorsin\\rpredargth)', 'human(classifyingerrorsinssyntpro)', 'human(coherence)', 'human(cohesion)', 'human(comparisonintermsof\"goodness\")', 'human(confidencescore)', 'human(consistency)', 'human(contentpreservation)', 'human(contentquality)', 'human(contradictions)', 'human(controllability)', 'human(correctness)', 'human(correctnessofnamedentity)', 'human(creativeness)', 'human(creativity)', 'human(detailedrelevant)', 'human(detectabilityofgeneratedvshumantext)', 'human(difficultyofarticulation)', 'human(distinctness)', 'human(entertainmentvalue)', 'human(erroranalysis)', 'human(factualaccuracy)', 'human(faithfulness)', 'human(fluency)', 'human(fluency,faithfulness,coverage,repetition)', 'human(fluency,relatedness,correctness,diversity)', 'human(grammaticality)', 'human(informativeness)', 'human(informativity)', 'human(intelligibility)', 'human(intentedsentiment)', 'human(interesting)', 'human(intrestingness)', 'human(linguisticqualities)', 'human(meaningpreservation)', 'human(morphologicalcorrectnessofnovelwords)', 'human(naturalness)', 'human(newinformation)', 'human(ontopic)', 'human(overall)', 'human(overalquality/preference)', 'human(perceivedappraisal)', 'human(perceivedemotion)', 'human(personalpreference)', 'human(propertythresholds)', 'human(quality)', 'human(rationality,fluency)', 'human(realisticevent)', 'human(relatedness)', 'human(relevance)', 'human(rhymequality)', 'human(semanticalcoherence)', 'human(semanticsuitabilityofnovelwords)', 'human(sentimentrelevance)', 'human(simplicitiy,correctness,fluency)', 'human(simplicity)', 'human(singability)', 'human(style)', 'human(styletransferaccuracy)', 'human(sucessrate)', 'human(summaryquality)', 'human(syntacticcorrectnessofnovelwords)', 'human(textplancoherence)', 'human(textplanredundancy)', 'human(textquality)', 'human(topicality)', 'human(topicrelevance)', 'human(toxicity)', 'human(unclear)', 'human(worderror)', 'human(writtenbyahuman)', 'human(writtenbyanartificialintelligence)', 'humancoherence', 'humancorrelation', 'humanfluency', 'humanfluencypreference', 'humaninformativeness', 'humanintheloopfactverificationwithgpt4', 'humanoutsideinformationpresence', 'humanvaluecorectness', 'ibleu', 'inferencetime', 'inform', 'initialphoneticoverlap', 'integrity', 'intentedsentiment(externalclassifier)', 'intentedsentiment(internalclassifier)', 'j(acc,sim,fl)', 'jensenshannondivergenceoflearneddistribution', 'keep', 'knowledgef1', 'knowledgeprecision', 'knowledgerecall', 'latency', 'length', 'lens', 'lexicalrepetition', 'localrecall', 'lr(lexicalrepetition)', 'macrof1', 'mauve', 'mauve(electralarge)', 'mauve(gpt2large)', 'mauve(robertalarge)', 'mauvescore', 'meansegmentedtypetokenratio', 'meteor', 'microf1', 'mlmppl', 'moverscore', 'mpnetcosinesimilarity', 'msjaccard', 'naturalness', 'negativesentiment', 'negbleurt', 'negmpnetcosinesimilarity', 'nehr', 'neroverlap', 'ngramnovelty(nfrom110)', 'nist', 'nist1', 'nist2', 'nist3', 'nist4', 'nli', 'nliwarmup', 'novelty', 'nubiaagreement', 'nubiacontradiction', 'nubianeutrality', 'nubiasemanticsimilarity', 'numberoftypes', 'parent', 'parenttf1', 'parenttprecision', 'parenttrecall', 'pbleu', 'percentageofnoveltexts', 'perplexity', 'perplexity(cgpt2)', 'perplexity(gpt2)', 'personalpronounoccurrence', 'phoneticoverlap', 'pmultipleattributeevaluation(pmae)', 'pnli', 'positiveness', 'ppl', 'precision', 'precision(lexicalsimplification)', 'prescomb', 'prismqe', 'propernounratio(pratio)', 'proportionofsentenceswithcomparatorwords', 'psim', 'purityscore', 'q^2', 'qaf1(informativeness/grounding)', 'qafacteval', 'questeval', 'rank', 'recall', 'recall(lexicalsimplification)', 'recalln', 'refbleu', 'relevance', 'repeatedtrigrams', 'repetitionrate', 'repnmetricsforn=2,3,4', 'reversecrossentropyoflearneddistribution', 'reversekldivergenceoflearneddistribution', 'rmseinprediction', 'robertafinetunedforsentiment', 'rouge', 'rouge1', 'rouge1context(r1c)', 'rouge1f1', 'rouge1proper(r1p)', 'rouge1propercontext(r1pc)', 'rouge2', 'rouge2(r2)', 'rouge2f1', 'rougeamg', 'rougeamr', 'rougef1', 'rougel', 'rougelf1', 'rougelsum', 'rouge{1,2,l}', 'rouge{1,2}', 's(simplicitygain)', 'salientwordcoverage', 'sari', 'selfbleu', 'selfbleu4', 'semanticsimilarity', 'sentbertcosine', 'sentencebert', 'sentencecount', 'sentencelength', 'sentencelevelbleu', 'sentiment', 'sentimentaccuracy', 'simcse', 'simileconfidence', 'simplicity', 'slotcoverage', 'smart', 'song8k', 'spearmanrankcorrelation', 'speed(tokenpers)', 'sr(semanticrepetition)', 'standarddeviationofthesentencelength', 'stressdurationalignment', 'structuref1', 'styleaccuracy', 'styletransferaccuracy', 'success', 'summac', 'syntacticnovelty(dependencylevel)', 'syntacticnovelty(sentencelevel)', 'ter', 'textblob', 'throughput', 'topic', 'topicmodelling', 'totalvariationdistanceoflearneddistribution', 'toxicity', 'transitionaccuracy', 'unieval', 'unieval(dial)', 'unieval(summ)', 'unievalcoherence', 'unievalconsistency', 'unievalfluency', 'unievaloverall', 'unievalrelevance', 'uniquesentencecount', 'usr', 'wecheck', 'weightedmacrof1', 'weisfeilerlehmangraphhash', \"zipf'scoefficient\", 'δcr']\n"]}]},{"cell_type":"code","source":["uni = set ()\n","for fs in df[TASK].unique():\n","  uni.update(fs)\n","uni"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtSDqyKo4EGn","executionInfo":{"status":"ok","timestamp":1715670544317,"user_tz":-120,"elapsed":10,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}},"outputId":"0c841ff2-722e-4e86-977b-c0d6e39f394a"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'',\n"," 'abductive nlg',\n"," 'abductive nli',\n"," 'classification as generation',\n"," 'commonsense reasoning',\n"," 'compare probability distribution for one step text generation (surface realisation)',\n"," 'compression / lossy simplification',\n"," 'content selection/determination',\n"," 'data-to-text generation',\n"," 'dialogue turn generation',\n"," 'end-to-end text generation',\n"," 'evaluate semantic diversity between two natural language generation',\n"," 'evaluation',\n"," 'feature-controlled generation',\n"," 'lexicalisation',\n"," 'machine translation',\n"," 'mixinstruct (instruction-based nlg)',\n"," 'multi-user dialogues',\n"," 'multilingual semantic textual similarity',\n"," 'multimodal-to-text',\n"," 'multiple (list all)',\n"," 'next action generation',\n"," 'next word prediction',\n"," 'open-ended text generation (lm sampling)',\n"," 'other (please specify)',\n"," 'paraphrasing / lossless simplification',\n"," 'prompt continuation',\n"," 'question answering',\n"," 'question classification',\n"," 'question generation',\n"," 'referring expression generation',\n"," 'semantic textual similarity',\n"," 'simile generation (text-to-text)',\n"," 'song lyric generation',\n"," 'story generation',\n"," 'summarisation (text-to-text)',\n"," 'surface realisation (slr to text)',\n"," 'text reframing',\n"," 'text to graph',\n"," 'text-to-text generation',\n"," 'translation',\n"," 'zero-shot entity linking'}"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# First take a look at papers with no metrics at all\n","no_metrics = df[df[METRIC_NAME] == \"\"]\n","num_no_metrics = len(no_metrics[ID].unique())\n","df_all = df[df[METRIC_NAME] != \"\"]\n","num_with_all = len(df_all[ID].unique())\n","print(f\"There are {num_no_metrics} papers with no metrics, {num_with_all} papers remain for analysis.\")\n","\n","# Now exclude papers with only human metrics, but also report how many papers uses human metrics\n","hum_df = df[df[METRIC_NAME].str.contains('human')]\n","papers_hum = len(hum_df[ID].unique())\n","num_h = len(hum_df)\n","print(f\"{papers_hum} out of {len(df)} papers use human evaluation. In total, there were {num_h} human metrics used.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"al0Hi9ur6j8G","executionInfo":{"status":"ok","timestamp":1715670544317,"user_tz":-120,"elapsed":5,"user":{"displayName":"Patricia Schmidtova","userId":"06572757679288945207"}},"outputId":"3c876bf7-a732-4896-9815-f0dab0730f72"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 2 papers with no metrics, 102 papers remain for analysis.\n","57 out of 746 papers use human evaluation. In total, there were 131 human metrics used.\n"]}]}]}